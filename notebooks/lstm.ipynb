{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-19T12:20:07.648971",
     "start_time": "2017-03-19T12:20:07.416045"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
<<<<<<< HEAD
    "warnings.filterwarnings('ignore')\n",
    "%run ../prepare_data.py -N_users 10"
=======
    "warnings.filterwarnings('ignore')"
>>>>>>> 8677288227558d2f31ce2ea4002d2ed155c9d2c9
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-19T12:25:26.423231",
     "start_time": "2017-03-19T12:20:23.259555"
    },
    "collapsed": false
   },
   "outputs": [
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18651, 82)\n"
=======
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
>>>>>>> 8677288227558d2f31ce2ea4002d2ed155c9d2c9
     ]
<<<<<<< HEAD
    }
   ],
   "source": [
    "%run ../lstm.py -N_train 100 -N_test 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-19T00:37:24.936968",
     "start_time": "2017-03-19T00:37:24.932357"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "(2261, 82)\n"
=======
      "(17945, 82)\n",
      "(2151, 82)\n"
>>>>>>> 8677288227558d2f31ce2ea4002d2ed155c9d2c9
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 4,
>>>>>>> 8677288227558d2f31ce2ea4002d2ed155c9d2c9
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-19T00:37:24.975863",
     "start_time": "2017-03-19T00:37:24.938776"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"/home/ramya/anaconda3/lib/python3.6/site-packages/tensorflow/python/__init__.py\", line 61, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"/home/ramya/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n  File \"/home/ramya/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\n  File \"/home/ramya/anaconda3/lib/python3.6/imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/home/ramya/anaconda3/lib/python3.6/imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: libcudart.so.8.0: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/home/ramya/anaconda3/lib/python3.6/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdlopenflags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_default_dlopen_flags\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRTLD_GLOBAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdlopenflags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_default_dlopen_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ramya/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0m_pywrap_tensorflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ramya/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0m_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_pywrap_tensorflow'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ramya/anaconda3/lib/python3.6/imp.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(name, file, filename, details)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ramya/anaconda3/lib/python3.6/imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[0;34m(name, path, file)\u001b[0m\n\u001b[1;32m    341\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libcudart.so.8.0: cannot open shared object file: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7486fd66b1dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRMSprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ramya/anaconda3/lib/python3.6/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ramya/anaconda3/lib/python3.6/site-packages/keras/activations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ramya/anaconda3/lib/python3.6/site-packages/keras/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown backend: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_BACKEND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ramya/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_array_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ramya/anaconda3/lib/python3.6/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ramya/anaconda3/lib/python3.6/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# Protocol buffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"/home/ramya/anaconda3/lib/python3.6/site-packages/tensorflow/python/__init__.py\", line 61, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"/home/ramya/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n  File \"/home/ramya/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\n  File \"/home/ramya/anaconda3/lib/python3.6/imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/home/ramya/anaconda3/lib/python3.6/imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: libcudart.so.8.0: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
=======
      "(17945, 82) (2151, 82)\n",
      "(5962, 60, 16)\n",
      "(5962, 16)\n",
      "(697, 60, 16)\n",
      "(697, 16)\n"
>>>>>>> 8677288227558d2f31ce2ea4002d2ed155c9d2c9
     ]
    }
   ],
   "source": [
    "X_train, y_train = reformat(df_train)\n",
    "X_test,y_test=reformat(df_test)\n",
    "\n",
    "print(df_train.shape,df_test.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-19T00:37:25.624322",
     "start_time": "2017-03-19T00:37:24.977747"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(131078)\n",
    "model, filepath = get_model(1)\n",
    "# Define callback to save model\n",
    "save_snapshots = ModelCheckpoint(filepath,\n",
    "                                 monitor='loss',\n",
    "                                 save_best_only=True,\n",
    "                                 save_weights_only=True,\n",
    "                                 mode='min',\n",
    "                                 verbose=0)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 6,
>>>>>>> 8677288227558d2f31ce2ea4002d2ed155c9d2c9
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-19T00:37:49.030848",
     "start_time": "2017-03-19T00:37:35.683342"
=======
>>>>>>> 3e263b9ab7943944152620bfc0748e716689e3ae
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
<<<<<<< HEAD
      "Build model...\n",
      "Train on 6804 samples, validate on 643 samples\n",
      "Epoch 1/3\n",
      "6804/6804 [==============================] - 8s - loss: 0.5872 - acc: 0.9480 - val_loss: 0.1868 - val_acc: 0.9779\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/3\n",
      "6804/6804 [==============================] - 7s - loss: 0.1141 - acc: 0.9831 - val_loss: 0.1076 - val_acc: 0.9779\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/3\n",
      " 512/6804 [=>............................] - ETA: 7s - loss: 0.0924 - acc: 0.9819"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5f1dd32f22eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                     verbose=1)          \n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ramya/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    843\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/ramya/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ramya/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ramya/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2073\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2075\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2076\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ramya/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ramya/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ramya/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ramya/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ramya/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
=======
      "Train on 5962 samples, validate on 697 samples\n",
=======
      "Train on 6127 samples, validate on 571 samples\n",
>>>>>>> 3e263b9ab7943944152620bfc0748e716689e3ae
      "Epoch 1/3\n",
      "6127/6127 [==============================] - 82s - loss: 0.2424 - acc: 0.9634 - val_loss: 0.0788 - val_acc: 0.9852\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/3\n",
      "6127/6127 [==============================] - 82s - loss: 0.0984 - acc: 0.9822 - val_loss: 0.0748 - val_acc: 0.9852\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/3\n",
      "6127/6127 [==============================] - 82s - loss: 0.0960 - acc: 0.9823 - val_loss: 0.0750 - val_acc: 0.9852\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Test score: 0.0749978427131\n",
      "Test accuracy: 0.985223293304\n"
     ]
>>>>>>> 8677288227558d2f31ce2ea4002d2ed155c9d2c9
    }
   ],
   "source": [
<<<<<<< HEAD
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    nb_epoch=NB_EPOCH,\n",
    "                    validation_data=(X_test, y_test),\n",
<<<<<<< HEAD
    "                    callbacks=callbacks_list,\n",
    "                    verbose=2)          \n",
=======
    "                    callbacks=[save_snapshots],\n",
    "                    verbose=1)          \n",
>>>>>>> 8677288227558d2f31ce2ea4002d2ed155c9d2c9
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=2)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])  \n",
    "\n",
    "plot_logs(history) "
=======
    "%run ../lstm.py -N_train 100 -N_test 10 -N_epochs 3 -fit"
>>>>>>> 3e263b9ab7943944152620bfc0748e716689e3ae
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-19T12:25:33.856312",
     "start_time": "2017-03-19T12:25:33.544348"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmMAAAEICAYAAAATE/N5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xl8VdW5//HPkwFCAAUCIhgUVFQQJSriPFAcAJWhvdef\nWtRrtYgDzla01rEDddbKcLHlXu/1amtVBhUVUSy2OIAYJSrI4EAYA8hMIMPz+2Pv4CEEcgJJ9sk5\n3/frlVf2WXutfZ6N5uTJWmuvZe6OiIiIiEQjLeoARERERFKZkjERERGRCCkZExEREYmQkjERERGR\nCCkZExEREYmQkjERERGRCCkZExEREYmQkjGJjJldYmazzGyjmS0zszfM7NS9uN63ZnZWbcYoIsnP\nzN4zsx/MrHHUsUhqUjImkTCzW4AngN8DbYEDgZFA/yjjEpHUYmYdgdMApx4/f8wso77eSxKfkjGp\nd2a2L/AAcJ27v+Lum9y9xN1fc/dfmVljM3vCzJaGX09U/MVqZq3N7DUzW2tma8zsfTNLM7P/JUjo\nXg172n4V5T2KSINxGfAh8N/A5RWFZtbEzB41s+/MbJ2Z/dPMmoTnTjWzGeHn0GIz+4+w/D0zuyrm\nGv9hZv+Mee1mdp2ZzQfmh2VPhtdYb2afmNlpMfXTzewuM1toZhvC8x3MbKSZPRp7E2Y2ycxurot/\nIKl7SsYkCicBWcD4XZz/NXAikAd0B3oCd4fnbgUKgTYEPWp3Ae7ulwLfAxe4ezN3f6juwheRJHIZ\n8H/h17lm1jYsfwQ4DjgZaAX8Cig3s4OAN4A/EXwO5QH5NXi/gcAJQNfw9czwGq2A54G/m1lWeO4W\n4GKgH7AP8AtgM/AscLGZpUHwRypwVtheGiAlYxKFHGCVu5fu4vzPgQfcfaW7FwH3A5eG50qAdsBB\nYW/a+64NVkVkD4RzVA8CXnT3T4CFwCVhkvML4EZ3X+LuZe4+w923ApcAU939hfAzaLW71yQZ+4O7\nr3H3LQDu/lx4jVJ3fxRoDBwe1r0KuNvd53ngs7Dux8A6oHdY7yLgPXdfsZf/JBIRJWMShdVA693M\nmWgPfBfz+ruwDOBhYAEwxcwWmdnwugtTRJLc5cAUd18Vvn4+LGtN0Hu/sIo2HXZRHq/FsS/M7DYz\n+yocCl0L7Bu+f3Xv9SwwODweDPzvXsQkEVMyJlH4ANhK0F1flaUEf61WODAsw903uPut7n4wwWTb\nW8ys4q9D9ZCJSFzC+V8XAmeY2XIzWw7cTDA1oh1QDBxSRdPFuygH2ARkx7zev4o62z+nwvlhvwrj\naOnuLQh6vCyO93oOGGBm3YEuwIRd1JMGQMmY1Dt3XwfcA4w0s4Fmlm1mmWbW18weAl4A7jazNuFc\niHsIPngws/PN7FAzM4IPrTKgPLz0CuDger8hEWmIBhJ8fnQlmLOVR5DUvE8wj2wc8JiZtQ8n0p8U\nPkj0f8BZZnahmWWYWY6Z5YXXzAd+Gn6mHQpcWU0MzYFSoAjIMLN7COaGVfgz8KCZdbbA0WaWA+Du\nhQTzzf4XeLli2FMaJiVjEolwbsQtBBPziwj+Arye4K+73wKzgM+BOcDssAygMzAV2EjQwzbK3aeF\n5/5AkMStNbPb6ulWRKRhuhz4L3f/3t2XV3wBTxPMWx1O8PkzE1gD/BFIc/fvCSbU3xqW5xP0pgE8\nDmwj+MPwWYLEbXfeAt4EviaYjlHMjsOYjwEvAlOA9cBfgCYx558FjkJDlA2eae6ziIhIw2NmpxOM\nGhykB5kaNvWMiYiINDBmlgncCPxZiVjDp2RMRESkATGzLsBaggcNnog4HKkFcSVjZtbHzOaZ2YKq\nlhIws5+b2edmNidclbh7zLlvw/J8M5sVU97KzN42s/nh95a1c0siIiLJy92/cvem7n6yu6+POh7Z\ne9UmY2aWTrBnYF+Cp04uNrOulap9A5zh7kcBDwJjK53v5e557t4jpmw48I67dwbeCV+LiIiIpJR4\nNirtCSxw90UAZvZXYADwZUUFd58RU/9DIDeO6w4AzgyPnwXeA+7YXYPWrVt7x44d47i0iCSLTz75\nZJW7t4k6jr2lzy+R1BPv51c8ydgB7PiobSHBvlq7ciXBvl0VHJhqZmXAf7p7Ra9ZW3dfFh4vJ9hn\ncCdmNgQYAnDggQcya9asqqqJSJIys++qr5X4OnbsqM8vkRQT7+dXPMlYTd60F0EydmpM8anuvsTM\n9gPeNrO57j49tp27u5lV+TRImLyNBejRo4eeGBEREZGkEs8E/iUE+2NVyA3LdmBmRxOsFjzA3VdX\nlLv7kvD7SmA8wbAnwAozaxe2bQes3JMbEBEREWnI4knGZgKdzayTmTUi2B1+UmwFMzsQeAW41N2/\njilvambNK46Bc4CC8PQkghWQCb9P3JsbEREREWmIqh2mdPdSM7ueYNuGdGCcu39hZkPD82MI9g7M\nAUYFWwZSGj452RYYH5ZlAM+7+5vhpUcAL5rZlQTbQFxYq3cmkgRKSkooLCykuLg46lDqXFZWFrm5\nuWRmZkYdiohIvYprzpi7TwYmVyobE3N8FXBVFe0W8eOeXZXPrQZ61yRYkVRTWFhI8+bN6dixI+Ef\nNUnJ3Vm9ejWFhYV06tQp6nBEROqVVuAXSWDFxcXk5OQkdSIGYGbk5OSkRA+giEhlSsZEElyyJ2IV\nUuU+RUQqq9WlLRLGxiJ4/xHofS80yo46GhGJkJn1AZ4kmPP6Z3cfUel8S2AccAhQDPzC3QvCczcT\nTMFwYA5whbsXm9l9wC+BovAyd4XTOWrF/a9+wZdLtcuNSKLp2n4f7r3gyFq/bnL2jK38Ej4aA+8+\nGHUkIg3a2rVrGTVq1B61feKJJ9i8eXMtR1QzcW7ndheQ7+5HA5cRJG6Y2QHADUAPd+9GkMxdFNPu\n8XCbt7zaTMREJPUkZ8/YwWdAzyHw4Sg44jzoeGr1bURkJxXJ2LXXXlvjtk888QSDBw8mOzvS3ulq\nt3MjSNJGALj7XDPraGYVO4JkAE3MrATIBpbWR9B18Ze3iCSu5OwZAzjrPmh1MEy4FrZuiDoakQZp\n+PDhLFy4kLy8PG6//XYefvhhjj/+eI4++mjuvfdeADZt2sR5551H9+7d6datG3/729946qmnWLp0\nKb169aJXr15R3kJV27kdUKnOZ8BPAcysJ3AQkBsuWP0I8D2wDFjn7lNi2g0zs8/NbFw41LkTMxti\nZrPMbFZRUVFVVUREkrRnDKBRUxg4Gsb1gSm/gQueiDoikb1SF/OIqpv/MGLECAoKCsjPz2fKlCm8\n9NJLfPzxx7g7/fv3Z/r06RQVFdG+fXtef/11ANatW8e+++7LY489xrRp02jdunWtxlwHRgBPmlk+\nwbywT4GyMMEaAHQC1gJ/N7PB7v4cMBp4kGAu2YPAo8AvKl9Y27mJSDySt2cM4MAT4eRh8Ml/wYKp\nUUcj0qBNmTKFKVOmcMwxx3Dssccyd+5c5s+fz1FHHcXbb7/NHXfcwfvvv8++++4bdaixqt3Ozd3X\nu/sV7p5HMGesDbAIOAv4xt2L3L2EYJeRk8M2K9y9zN3LgWf4cZs3EZEaS96esQq9fg3zp8DEYXDt\nDGhS5WiCSMKLeh6Ru3PnnXdy9dVX73Ru9uzZTJ48mbvvvpvevXtzzz33RBBhlbZv50aQhF0EXBJb\nwcxaAJvdfRvBk5PT3X29mX0PnGhm2cAWgkWqZ4Vt2rn7svASg/hxmzcRkRpL7p4xgMwsGDQGNq6A\nN4ZHHY1Ig9K8eXM2bAjmXJ577rmMGzeOjRs3ArBkyRJWrlzJ0qVLyc7OZvDgwdx+++3Mnj17p7ZR\ncfdSoGI7t6+AFyu2c6vY0g3oAhSY2TyCpy5vDNt+BLwEzCYYvkwjHHIEHjKzOWb2OdALuLm+7klE\nkk/y94wBtD8GTr8N/vFH6HIBdDk/6ohEGoScnBxOOeUUunXrRt++fbnkkks46aSTAGjWrBnPPfcc\nCxYs4PbbbyctLY3MzExGjx4NwJAhQ+jTpw/t27dn2rRpkd1DHNu5fQActou29wL3VlF+aS2HKSIp\nzNwbzpzSHj16+KxZs/ascek2+HNv2LAMrv0Qmib8pGIRvvrqK7p06RJ1GPWmqvs1s0/cvUdEIdWa\nvfr8EpEGKd7Pr+QfpqyQ0SgYrixeB6/dDA0oCRUREZHklTrJGEDbI+HMO+GrSVDwctTRiIiIiKRY\nMgZw8g2Qezy8fitsWB51NCIiIpLiUi8ZS8+AgWOgdCtMukHDlSIiIhKp1EvGAFofGmyXNP8t+PS5\nqKMRERGRFJaayRgEG4l3PA3evBPWfh91NCIiIpKiUjcZS0uDAU8DDhOvg/LyqCMSSThr165l1KhR\nNW7Xr18/1q5dWwcRiYgkn9RNxgBadoRzfwffTIdZf4k6GpGEs6tkrLS0dLftJk+eTIsWLeoqLBGR\npJLayRjAsZfDoWfB2/fA6oVRRyOSUIYPH87ChQvJy8vj+OOP57TTTqN///507doVgIEDB3Lcccdx\n5JFHMnbs2O3tOnbsyKpVq/j222/p0qULv/zlLznyyCM555xz2LJlS1S3IyKSkOLaDsnM+gBPAunA\nn919RKXzPwfuAAzYAFzj7p+ZWQfgf4C2gANj3f3JsM19wC+BovAyd4XbltQvM+j/Jxh1Iky4Bq54\nA9LS6z0MkWq9MRyWz6nda+5/FPQdscvTI0aMoKCggPz8fN577z3OO+88CgoK6NSpEwDjxo2jVatW\nbNmyheOPP56f/exn5OTk7HCN+fPn88ILL/DMM89w4YUX8vLLLzN48ODavQ8RkQas2p4xM0sHRhJs\noNsVuNjMulaq9g1whrsfBTzIj5vplgK3untX4ETgukptH3f3vPCr/hOxCvu0h74Pw+KP4IORkYUh\nkuh69uy5PREDeOqpp+jevTsnnngiixcvZv78+Tu16dSpE3l5eQAcd9xxfPvtt/UVrohIgxBPz1hP\nYIG7LwIws78CA4AvKyq4+4yY+h8CuWH5MmBZeLzBzL4CDohtmzCOvjBYmf/dB6Hz2bBf6uwHKA3E\nbnqw6kvTpk23H7/33ntMnTqVDz74gOzsbM4880yKi4t3atO4cePtx+np6RqmFBGpJJ45YwcAi2Ne\nF4Zlu3Il8EblQjPrCBwDfBRTPMzMPjezcWbWsqqLmdkQM5tlZrOKioqqqlI7zOD8J6Bxcxg/FMpK\n6u69RBqI5s2bs2HDhirPrVu3jpYtW5Kdnc3cuXP58MMP6zk6EZHkUKsT+M2sF0Eydkel8mbAy8BN\n7r4+LB4NHAzkEfSePVrVNd19rLv3cPcebdq0qc1wd9asTZCQLcuH9x+r2/cSaQBycnI45ZRT6Nat\nG7fffvsO5/r06UNpaSldunRh+PDhnHjiiRFFKSLSsMUzTLkE6BDzOjcs24GZHQ38Gejr7qtjyjMJ\nErH/c/dXKsrdfUVMnWeA12ocfV3o2h+O+neY/hAc3gfadY86IpFIPf/881WWN27cmDfe2KkTHGD7\nvLDWrVtTUFCwvfy2226r9fhERBq6eHrGZgKdzayTmTUCLgImxVYwswOBV4BL3f3rmHID/gJ85e6P\nVWrTLublIKCARNH3IchuHQxXlm6NOhoRERFJYtX2jLl7qZldD7xFsLTFOHf/wsyGhufHAPcAOcCo\nIP+i1N17AKcAlwJzzCw/vGTFEhYPmVkewZIX3wJX1+qd7Y3sVsFyF8//O7z3h2AfSxEREYlWeTl4\nGZSXhd9Lw+PymOPw/A7HpeFxeaV2FcflVdfdfhxzrW4/C/KEWhTXOmNh8jS5UtmYmOOrgKuqaPdP\ngrXHqrrmpTWKtL4ddg4cexn860k4/DzocHzUEUmKcnfCP3KSmrtHHYJI/dnTpGKn5GFPE5Dd1K0q\nAakyzrId68YdZ6X3KC/98XrVvQcJ8Dlx0CnRJGMp65zfwcJpMGEoXP0+NMqOOiJJMVlZWaxevZqc\nnJykTsjcndWrV5OVlRV1KCK16x8PwYynwwQjwZKK3UnLAEsPFkGv+L7DcQZYWsxxxfm04PX2uhmQ\nngkZWZXqpv14Pp73qEnd3cZTVbvdxL49zpi6Tapc/GGvKBnbnax9YMBI+J/+8M4DCbHOk6SW3Nxc\nCgsLqdNlXRJEVlYWubm5UYchUnu+eR+m/Q4O7gVtj9yLpGBXdatKaHaRQMSd/IR1pV4pGavOwWdA\nz6vho9FwRD/odHrUEUkKyczM3GHFexFpILZugInXQqtD4KLnNbIiu6X0Nx5n3Rf8QE28LvgBExER\n2Z0pd8O6Qhg4WomYVEvJWDwaZQc/UOsKgx8wERGRXVkwFT75bzh5GBx4QtTRSAOgZCxeB54Q/GB9\n8t8wf2rU0YiISCLashYmDoM2R8CZd0UdjTQQSsZq4sy7oE0XmHQ9bPkh6mhERCTRvDkcNq6AQWMg\nU08HS3yUjNVEZhYMGg2biuCNO6qvLyIiqWPu6/DZC3D6bdD+mKijkQZEyVhNtT8GTrsNPv8bfPVq\n1NGIiEgi2LQaXr0R9j86+B0hUgNKxvbE6bcFP3Cv3gSbVkUdjYiIRO31W4L5YoPGQEajqKORBkbJ\n2J5Iz4RB/wlb18NrN4G2cRERSV0FL8OXE6DXXcHiriI1pGRsT7XtCr1+HQxVznkp6mhERCQKG1bA\n67fCAT3g5BuijkYaKCVje+PkYZDbEybfCuuXRR2NiIjUJ3d49QYo2RIMT6ZrUxvZM0rG9kZaerAY\nbOm24AdSw5UiIqkj/3n4+k3ofS+07hx1NNKAKRnbW60PhbPvh/lT4NP/jToaERGpD+sKgzXFDjoV\nThgadTTSwCkZqw3H/xI6ngZv3gk/fBd1NCIiUpfcYeL1UF4GA56GNP0qlb2j/4NqQ1oaDBgZHE+8\nDsrLo41HRETqzqxxsGganPtbaNUp6mgkCSgZqy0tD4Jzfw/fvg8z/xx1NCISMrM+ZjbPzBaY2fAq\nzrc0s/Fm9rmZfWxm3WLO3WxmX5hZgZm9YGZZYXkrM3vbzOaH31vW5z1JhNZ8A1N+A4f8BI67Iupo\nJEkoGatNx14Gh54Nb98DqxdGHY1IyjOzdGAk0BfoClxsZl0rVbsLyHf3o4HLgCfDtgcANwA93L0b\nkA5cFLYZDrzj7p2Bd8LXkuzKy2HCtZCWAf3/BGZRRyRJQslYbTILfkAzGsP4ocF8AhGJUk9ggbsv\ncvdtwF+BAZXqdAXeBXD3uUBHM2sbnssAmphZBpANLA3LBwDPhsfPAgPr7hYkYXw0Gr6fAX1HwL65\nUUcjSSSuZCyObv6fh138c8xshpl1r65t0nbz79MO+j0ChR/DjD9FHY1IqjsAWBzzujAsi/UZ8FMA\nM+sJHATkuvsS4BHge2AZsM7dp4Rt2rp7xeKCy4G2SHIr+hreeQAO7wfdL446Gkky1SZjcXbzfwOc\n4e5HAQ8CY+Nom7zd/Ef9G3S5AKb9DlZ+FXU0IrJ7I4AWZpYPDAM+BcrCPxAHAJ2A9kBTMxtcubG7\nO1DlIoNmNsTMZpnZrKKiojq7AaljZaUwYShkNoHzn9DwpNS6eHrGqu3md/cZ7v5D+PJDIDeOtsnb\nzW8G5z0OjfeB8VdDWUnUEYmkqiVAh5jXuWHZdu6+3t2vcPc8gjljbYBFwFnAN+5e5O4lwCvAyWGz\nFWbWDiD8vrKqN3f3se7ew917tGnTpjbvS+rTjCdhySdw3mPQXJ2gUvviScbi6eaPdSXwRhxt4+rm\nb7B/WTZrA+c/Dss+g/cfjToakVQ1E+hsZp3MrBHBBPxJsRXMrEV4DuAqYLq7rycYnjzRzLLNzIDe\nQEVX9yTg8vD4cmBiHd+HRGV5AUz7Axw5CLr9NOpoJEnV6gR+M+tFkIzdUZN2u+vmb9B/WXbtD0f/\nP5j+MCzNjzoakZTj7qXA9cBbBInUi+7+hZkNNbOKZdO7AAVmNo9gSsWNYduPgJeA2cAcgs/LsWGb\nEcDZZjafoAdtRD3dktSn0m3B8GSTltBPf1RL3YlnV9Nqu/kBzOxo4M9AX3dfHUfbFWbWzt2X7a6b\nv8Hr+0f4ZnrwdOXV/wietBSReuPuk4HJlcrGxBx/ABy2i7b3AvdWUb6aoKdMktn0h2H5HLjoBWia\nE3U0ksTi6RmLp5v/QIL5FJe6+9dxtk2Nbv4mLYPlLoq+gmm/jzoaERGJx5LZwRST7pfAEf2ijkaS\nXLXJWJzd/PcAOcAoM8s3s1m7axu2SZ1u/s5nw7GXw4yn4PuPoo5GRER2p6Q4GM1o1hb6/CHqaCQF\nxDNMGU83/1UEE1/jahuWp1Y3/7m/C/Yym3ANDP0nNMqOOiIREanKtN/Bqnkw+BVo0iLqaCQFaAX+\n+tK4ebCZ+JqF8M79UUcjIiJV+f7DYMHu466AQ1Onv0CipWSsPnU6HU4YCh+NCSb1i4hI4ti2KRi9\naHEgnPNg1NFIClEyVt963wutDoEJ10Hx+qijERGRClPvgzWLYOCoYDRDpJ4oGatvjbJh0BhYXwhT\nfh11NCIiArDoH/DxWDjxWuh4atTRSIpRMhaFDj3h5Btg9v/A/LejjkZEJLUVr4eJ10HOodD7nqij\nkRSkZCwqve6CNl1g4vWweU3U0YiIpK4pv4b1S2DgmGAzcJF6pmQsKhmNg+HKzavgjRrtHiUiIrXl\n6ynBKMUpN0KH46OORlKUkrEotc+D038Fc16ELydVX19ERGrP5jUwaRjs1xXOvDPqaCSFKRmL2mm3\nQLs8eO1m2FgUdTQiIqnjjTuC0YlBY7RvsERKyVjU0jODD4Kt6+H1m8E96ohERJLfl5OCUYnTfwXt\nukcdjaQ4JWOJYL8u8JO74atXYc7fo45GRCS5bVoVjEa0ywtGJ0QipmQsUZx0PXQ4ASbfBuuXRh2N\niEhycofXbgpGIwaNCUYnRCKmZCxRpKXDwNFQui2YUKrhShGR2jfnpWAUotevg1EJkQSgZCyR5BwC\nZz8AC6YGj1qLiEjtWb8sGH3I7QknD4s6GpHtlIwlmuOvCjYUf+su+OG7qKMREUkO7vDqDVC6NRie\nTEuPOiKR7ZSMJZq0NBgwErBge47y8qgjEhFp+D59DuZPgbPvD0YhRBKIkrFE1OJA6PMH+Pb9YONa\nERHZc2u/hzfvhI6nwfG/jDoakZ0oGUtUxwyGzufA1Ptg1YKooxERaZjKy4NRBjwYdUjTrz1JPPq/\nMlGZwQVPBatCTxgK5WVRRyQi0vDM+gt8Mx3O/R20PCjqaESqpGQske3TDs57FApnwoynoo5GRKRh\nWb0Q3r4HDj0Ljr086mhEdknJWKLr9jPoOgCm/R5WfBl1NCIiDUN5GUy4NljUtf+fgtEGkQQVVzJm\nZn3MbJ6ZLTCz4VWcP8LMPjCzrWZ2W0z54WaWH/O13sxuCs/dZ2ZLYs71q73bSiJmcN5j0HgfGH81\nlJVEHZGISOL7YCQs/hD6Pgz7tI86GpHdqjYZM7N0YCTQF+gKXGxmXStVWwPcADwSW+ju89w9z93z\ngOOAzcD4mCqPV5x398l7cR/JrWlruOBJWP45TH+k+voiIqls5Vx497dwxPlw9IVRRyNSrXh6xnoC\nC9x9kbtvA/4KDIit4O4r3X0msLtum97AQnfXSqZ7osv5cPRFMP1hWPpp1NGIiCSmstLgoafGzeD8\nxzU8KQ1CPMnYAcDimNeFYVlNXQS8UKlsmJl9bmbjzKxlVY3MbIiZzTKzWUVFRXvwtkmk7who1hbG\nD4WS4qijERFJPP98PPiD9bzHoNl+UUcjEpd6mcBvZo2A/sDfY4pHAwcDecAy4NGq2rr7WHfv4e49\n2rRpU+exJrQmLYOJqEVz4b3fRx2NiEhiWfY5/GMEdPs3OHJg1NGIxC2eZGwJ0CHmdW5YVhN9gdnu\nvqKiwN1XuHuZu5cDzxAMh0p1Op8Fx/0H/Osp+P6jqKMREUkMpVthwjWQnQP9Ho46GpEaiScZmwl0\nNrNOYQ/XRcCkGr7PxVQaojSzdjEvBwEFNbxm6jrnt9CiQzAvYtumqKMREYneP/4IKwqCxbKzW0Ud\njUiNVJuMuXspcD3wFvAV8KK7f2FmQ81sKICZ7W9mhcAtwN1mVmhm+4TnmgJnA69UuvRDZjbHzD4H\negE319pdJbvGzWHgaFizKNguSUQklRXOCuaK5Q2Gw/tEHY1IjWXEUylcdmJypbIxMcfLCYYvq2q7\nCcipovzSGkUqO+p4KpxwDXw0Onh8++Azoo5IRKT+lWwJHmpq3h76aC6tNExagb8h630P5BwabIJb\nvD7qaERE6t+7v4XV82HA05C1b9TRiOwRJWMNWaNsGDgG1i+Bt+6KOhoRkfr13Yxgpf3jr4JDekUd\njcgeUzLW0HU4Hk65CT79X/j6raijERGpH1s3Bk9PtjwIzro/6mhE9oqSsWRw5nDY70iYdANsXhN1\nNCIide/te+CH74KHmRo3izoakb2iZCwZZDSGQaNh8yp441dRRyOSUMysj5nNM7MFZja8ivMtzWx8\nuBvIx2bWLSw/3MzyY77Wm9lN4bn7zGxJzLl+9X1fKW3huzDrL3DSdXDQyVFHI7LXlIwli3bd4Yw7\nYM7f4YsJUUcjkhDMLB0YSbDwdFfgYjPrWqnaXUC+ux8NXAY8CeDu89w9z93zgOOAzcD4mHaPV5wP\nnziX+lC8DiZeD60Pg5/cHXU0IrVCyVgyOfVmaH8MvH4LbEzxfTxFAj2BBe6+yN23AX8FBlSq0xV4\nF8Dd5wIdzaxtpTq9gYXu/l1dByzVePMu2LAseHgps0nU0YjUCiVjySQ9M/iA2roRXrsJ3KOOSCRq\nBwCLY14XhmWxPgN+CmBmPYGD2HndxIuotIsIMCwc2hxnZi2renMzG2Jms8xsVlGR/kDaa/PehPzn\n4NRbIPe4qKMRqTVKxpLNfkcEXfdzX4PPX4w6GpGGYATQwszygWHAp0BZxclwG7j+wN9j2owGDgby\ngGXAo1Vd2N3HunsPd+/Rpk2bOgo/RWxeA6/eAG27BVMyRJJIXCvwSwNz0nUw93WYfHuwUv++lTsC\nRFLGEqBDzOvcsGw7d18PXAFgZgZ8AyyKqdIXmO3uK2LabD82s2eA12o9ctnR5NuChGzwy5DRKOpo\nRGqVesakRpv8AAAgAElEQVSSUVo6DBwF5SUwaZiGKyWVzQQ6m1mnsIfrImBSbAUzaxGeA7gKmB4m\naBUuptIQpZm1i3k5CCio9cjlR1+Mh4KXgx6x/Y+KOhqRWqdkLFnlHAJnPwAL34HZz0YdjUgk3L0U\nuB54C/gKeNHdvzCzoWY2NKzWBSgws3kEvWA3VrQ3s6bA2cArlS79kJnNMbPPgV7AzXV8K6lr40p4\n7RZof2zwkJJIEtIwZTLrcSV89Sq89Ws4+Exo2THigETqX7jsxORKZWNijj8ADttF201AThXll9Zy\nmFIVd3jtZti2CQaNgXT9ypLkpJ6xZJaWBgNGAgYTroPy8qgjEhGJ3+d/Cx5G6v0baHN41NGI1Bkl\nY8muRQfoOwK++yd8/J9RRyMiEp91S2Dyr6DDiXDitVFHI1KnlIylgryfw2F9YOp9sGp+1NGIiOye\ne/DwUXlJ8DBSWnrUEYnUKSVjqcAMLngSMrJgwjVQVhp1RCIiuzb72eDho7MfCB5GEklySsZSRfP9\n4bxHoXAmzHgq6mhERKr2w3fBQ0edzggeQhJJAUrGUkm3n0HXgTDt97Dii6ijERHZUXk5TLwOsODh\nozT9ipLUoP/TU4kZnPcYNGkB46+G0m1RRyQi8qOPx8K370OfPwQPH4mkiLiSMTPrY2bzzGyBmQ2v\n4vwRZvaBmW01s9sqnfs2XBwx38xmxZS3MrO3zWx++L3KjXalljXNCeaPLZ8D7z8SdTQiIoFVC4KH\njDqfA8cMjjoakXpVbTJmZunASIKVqbsCF5tZ10rV1gA3ALv67d7L3fPcvUdM2XDgHXfvDLwTvpb6\ncMR50P1imP4ILJkddTQikurKy4KHizIawwVPBb34Iikknp6xnsACd1/k7tuAvwIDYiu4+0p3nwmU\n1OC9BwAV+/Q8CwysQVvZW31GQLO2MH4olBRHHY2IpLIZf4LCj6HfI7BPu+rriySZeJKxA4DFMa8L\nw7J4OTDVzD4xsyEx5W3dfVl4vBxoW1VjMxtiZrPMbFZRUVEN3lZ2q0kLGPA0rJoH034bdTQikqpW\nfAnTfgdd+sNR/xZ1NCKRqI8J/Ke6ex7BMOd1ZnZ65Qru7gRJ207cfay793D3Hm3atKnjUFPMob3h\nuCtgxtPw/YdRRyMiqaasBCYMhcb7wPmPa3hSUlY8ydgSIPaxltywLC7uviT8vhIYTzDsCbDCzNoB\nhN9XxntNqUXnPAgtDgyGK7dtijoaEUkl7z8Kyz6DC56Apq2jjkYkMvEkYzOBzmbWycwaARcBk+K5\nuJk1NbPmFcfAOUBBeHoScHl4fDkwsSaBSy1p3DzYbuSHb+Hte6OORkRSxdJ8mP4wHP3/oMsFUUcj\nEqmM6iq4e6mZXQ+8BaQD49z9CzMbGp4fY2b7A7OAfYByM7uJ4MnL1sB4C7qeM4Dn3f3N8NIjgBfN\n7ErgO+DC2r01iVvHU4ONeD8cCV3Oh4PPjDoiEUlmpVuD3vimbaDvH6OORiRy1SZjAO4+GZhcqWxM\nzPFyguHLytYD3XdxzdVA77gjlbrV+zcwfwpMvB6u+Rdk7Rt1RCKSrN77AxR9BT9/CZpoiUkRrcAv\ngcwmMGgMrF8Cb90VdTQikqwWz4R/PQnHXgadz446GpGEoGRMfpTbA069GT59Dua9WX19EZGa2LY5\neHpyn1w453dRRyOSMJSMyY7OuAPadoNXb4DNa6KORkSSyTsPwOoFMHAkZO0TdTQiCUPJmOwoozEM\nHA2bV8Pk26OORkSSxTfvw0ejoefV0Gmn5SZFUpqSMdlZu6PhjOFQ8BJ8MT7qaESkodu6ASZeC60O\nhrO0hI5IZUrGpGqn3gztj4XXboGNWo9XRPbClN/AukIYOAYaNY06GpGEo2RMqpaeETxduW0TvHoT\neJW7VYmI7N6CqfDJf8FJ18OBJ0QdjUhCUjImu9bmcOh9D8x7HT7/W9TRiEhDs2UtTBwGbY6AXr+O\nOhqRhKVkTHbvxGvgwJNg8q9gXdxbkoqIwJvDYeOKoJc9MyvqaEQSlpIx2b209GDvyvISmHS9hitF\nJD5zX4fPXoDTb4P2x0QdjUhCUzIm1Wt1MJzzICx8N5j7ISKyO5tWw6s3wv5HwWm3RR2NSMJTMibx\n6XElHNwL3rob1nwTdTQiksgm3xrMFxv0n5DRKOpoRBKekjGJjxkMeDoYtpx4HZSXRx2RiCSigpeD\n9Ql73Qltj4w6GpEGQcmYxG/fXOgzAr77F3w0JupoRCTRbFgBr98KB/SAk2+MOhqRBkPJmNRM3iVw\nWF94535YNT/qaEQkUbgHe9qWbAmenkzPiDoikQZDyZjUjBlc8CRkNoHxQ6GsNOqIRCQR5D8PX78J\nve+F1p2jjkakQVEyJjXXvC2c9ygsmQUznow6GhGJ2rrCYE2xg06BE4ZGHY1Ig6NkTPZMt5/BkYNg\n2h9geUHU0YhIVNxh4vVQXgYDRkKafq2I1JR+amTP9XsUmrQMhitLt0UdjYhEYdY4WDQtWIuwVaeo\noxFpkJSMyZ5rmhPMH1sxB6Y/FHU0IlLf1nwDU34TrEHY4xdRRyPSYCkZk71zRD/ofgm8/xgs+STq\naER2YmZ9zGyemS0ws+FVnG9pZuPN7HMz+9jMuoXlh5tZfszXejO7KTzXyszeNrP54feW9X1fkSsv\nhwnXBmsPDng6eLhHRPZIXMlYHB9mR5jZB2a21cxuiynvYGbTzOxLM/vCzG6MOXefmS2J+aDrVzu3\nJPWuzx+g+f4w/prgsXaRBGFm6cBIoC/QFbjYzLpWqnYXkO/uRwOXAU8CuPs8d89z9zzgOGAzMD5s\nMxx4x907A++Er1PLR6Ph+xnQ94/BGoQisseqTcbi/DBbA9wAPFKpvBS41d27AicC11Vq+3jFh527\nT97Tm5CINWkB/f8Eq+bBu7+NOhqRWD2BBe6+yN23AX8FBlSq0xV4F8Dd5wIdzaxtpTq9gYXu/l34\negDwbHj8LDCwLoJPWEVfwzsPBGsOdr846mhEGrx4esaq/TBz95XuPhMoqVS+zN1nh8cbgK+AA2ol\nckksh/YO9q/8YCR8NyPqaEQqHAAsjnldyM6fQZ8BPwUws57AQUDlrp6LgBdiXrd192Xh8XKgcvJG\neL0hZjbLzGYVFRXt2R0kmrJSmDA0WGvwgic1PClSC+JJxuL5MKuWmXUEjgE+iikeFs7TGLerORdJ\n+WGWrM5+AFoeBBOuga0bo45GJF4jgBZmlg8MAz4FyipOmlkjoD/w96oau7sDvotzY929h7v3aNOm\nTa0HHokZTwbzQ897NFhzUET2Wr1M4DezZsDLwE3uvj4sHg0cDOQBy4BHq2qblB9myapxMxgwCn74\nDqbeG3U0IgBLgA4xr3PDsu3cfb27XxHODbsMaAMsiqnSF5jt7itiylaYWTuA8PvKugg+4SwvCNYW\nPHJQsNagiNSKeJKxaj/MdsfMMgkSsf9z91cqyt19hbuXuXs58AzBcKg0dB1PgZOug5l/hoXvRh2N\nyEygs5l1Cnu4LgImxVYwsxbhOYCrgOkxfzQCXMyOQ5SE17g8PL4cmFjrkSea0m3B8GSTFsEagyJS\na+JJxqr9MNsVMzPgL8BX7v5YpXPtYl4OArSMe7L4yd3Q+rBgVe7idVFHIynM3UuB64G3COasvuju\nX5jZUDOr2LenC1BgZvMIesFin/puCpwNvLLjlRkBnG1m84GzwtfJbfrDsHwOXPBUsMagiNSajOoq\nuHupmVV8mKUD4yo+zMLzY8xsf2AWsA9QHq7F0xU4GrgUmBPOxwC4K3xy8iEzyyOYa/EtcHXt3ppE\nJrMJDBwDfzkL3rwLBo6MOiJJYeHnzeRKZWNijj8ADttF203ATpmHu68meMIyNSyZDe8/Gjw5eYRW\nIRKpbdUmYxDXh9lydn76COCfQJWP2rj7pfGHKQ1O7nFw6i3w/iPQ5Xw4vG/UEYnInigpDrY8a9YW\n+iR/B6BIFLQCv9SdM+6Att1g0g2weU3U0YjInpj2u2ANwQF/CuaLiUitUzImdSejEQwaA1t+gNdv\njToaEamp7z+EGX+C466AQ8+KOhqRpKVkTOrW/kfBmcPhi1egoPIcaBFJWNs2BWsGtugA5zwYdTQi\nSU3JmNS9U26CA44Lesc2rKi+vohEb+p9sGYRDBwNjZtHHY1IUlMyJnUvPSN4urJkM7x2E3iVi5WL\nSKJY9A/4eCyccA10PDXqaESSnpIxqR9tDoPe98C8yfBZ5fUzRSRhFK+HiddBzqHBz6yI1DklY1J/\nTrgGDjoF3hgO6wqjjkZEqjLl17B+SdCb3Sg76mhEUoKSMak/aWkwYCSUlwar82u4UiSxfD0FZv8P\nnHIjdDg+6mhEUoaSMalfrToFT2YtmgazxkUdjYhU2LwGJg2D/brCmXdGHY1ISlEyJvWvxy/g4F4w\n5Tew5puooxERgDfugM2rgqcnMxpHHY1ISlEyJvXPDAY8DWkZMOFaKC+POiKR1PblJJjzIpx+O7TP\nizoakZSjZEyisW8u9B0B38+Aj0ZHHY1I6tq0Cl67Gdp1h9O0U4ZIFJSMSXS6XwyH94Op90PRvKij\nEUk97sHaf1vXw6D/hPTMqCMSSUlKxiQ6ZnD+E9CoKYwfCmWlUUckklrmvARfvQq9fg37dYk6GpGU\npWRMotW8LZz/GCydDf96IupoRFLH+mUw+TbI7QknD4s6GpGUpmRMonfkIDjyp/DeCFg+J+poRJKf\nO7x6A5RuDZ6eTEuPOiKRlKZkTBLDeY9Ck5bBcGXptqijEUlunz4H86fAWfdB60OjjkYk5SkZk8SQ\n3Qr6PwUrCuAff4w6GpHktfZ7ePNO6Hga9BwSdTQigpIxSSSH94W8wfDPx6Dwk6ijEUk+5eXBJuB4\nsDVZmn4FiCQC/SRKYunze2jeHiYMhZItUUcjklxm/QW+mQ7n/g5aHhR1NCISiisZM7M+ZjbPzBaY\n2fAqzh9hZh+Y2VYzuy2etmbWyszeNrP54feWe3870uBl7Ruszr/qa3j3t1FHI5I8Vi+Et++BQ8+C\nYy+POhoRiVFtMmZm6cBIoC/QFbjYzLpWqrYGuAF4pAZthwPvuHtn4J3wtQgc0guOvwo+GAnf/ivq\naEQavvKyYOux9Ezo/6dgjT8RSRjx9Iz1BBa4+yJ33wb8FRgQW8HdV7r7TKCkBm0HAM+Gx88CA/fw\nHiQZnXU/tOwIE66BrRujjkakYftwFCz+EPo+BPu0jzoaEakknmTsAGBxzOvCsCweu2vb1t2XhcfL\ngbZVXcDMhpjZLDObVVRUFOfbSoPXuFmw/tHa74OhFRHZMyvnwjsPwhHnw9H/L+poRKQKGVEHAODu\nbma+i3NjgbEAPXr0qLKOJKmDToKTroMPnoYtPwTbJqU3Cr4ywu/pjYOhlx3KKn1VVb6ruukJ8SMh\nUjvKSoOHYRo1hfMf1/CkSIKK5zfPEqBDzOvcsCweu2u7wszaufsyM2sHrIzzmpJKfvIbWPNNsF1S\n6TYoi/kq3QrUcn5uaVUkaJmQ0fjH44oEcKey2LqZVSSLjXdsv0PZrurGJpCNIS1Dv1Alfv98HJZ+\nCv/+LDTbL+poJAWVlJRQWFhIcXFx1KHUqaysLHJzc8nMzNyj9vEkYzOBzmbWiSCRugi4JM7r767t\nJOByYET4fWIN4pZUkZkFFz+/6/NlpTsmaNsTtTjLdigvgbKtu6lbEiSAFcdbfqhUHtO+oszLav/f\npMY9gjHJYpV140ksK5ftom5aptauShTLPg8WUO72MzhSU3IlGoWFhTRv3pyOHTtiSfqHpLuzevVq\nCgsL6dSp0x5do9pkzN1Lzex64C0gHRjn7l+Y2dDw/Bgz2x+YBewDlJvZTUBXd19fVdvw0iOAF83s\nSuA74MI9ugNJbekZ4dBidtSRVK28LCZJK/mxR6+qxK3i/F7XDZPHrRt2LqucgJZXfuamFqRl7L5H\ncL8u8NOxtf++8qPSbcHDL9mtoN8j1dcXqSPFxcVJnYgBmBk5OTnszbz2uCbIuPtkYHKlsjExx8sJ\nhiDjahuWrwZ61yRYkQYnLT34ysyKOpKqudeg53BXvYQ1qVsSrCUndesffwy2Frv4b0FCJhKhZE7E\nKuztPWq2skgqMwt6rjIaQ+Oog5FaUfhJsKVY3mA4vE/U0YhIHDS5Q0QkWZRsCZ6ebN4+2FpMJMWt\nXbuWUaNG7VHbJ554gs2bN9dyRFVTMiYikize/W2wldiApzUcLELDScY0TCkikgy+mxFsIdbjymBL\nMZEEc/+rX/Dl0vW1es2u7ffh3guO3OX54cOHs3DhQvLy8jj77LPZb7/9ePHFF9m6dSuDBg3i/vvv\nZ9OmTVx44YUUFhZSVlbGb37zG1asWMHSpUvp1asXrVu3Ztq0abUad2VKxkREGrqtG4OnJ1seBGc/\nEHU0IgljxIgRFBQUkJ+fz5QpU3jppZf4+OOPcXf69+/P9OnTKSoqon379rz++usArFu3jn333ZfH\nHnuMadOm0bp16zqPU8mYiEhDN/Ve+OE7uGJysJWYSALaXQ9WfZgyZQpTpkzhmGOOAWDjxo3Mnz+f\n0047jVtvvZU77riD888/n9NOO63eY9OcMRFJambWx8zmmdkCMxtexfmWZjbezD43s4/NrFvMuRZm\n9pKZzTWzr8zspLD8PjNbYmb54Ve/+rynHSx8F2b+Odg67KCTIwtDJNG5O3feeSf5+fnk5+ezYMEC\nrrzySg477DBmz57NUUcdxd13380DD9R/77KSMRFJWmaWDowE+gJdgYvNrGulancB+e5+NHAZ8GTM\nuSeBN939CKA78FXMucfdPS/82mktxXpRvA4mXg+tD4Of3B1JCCKJrHnz5mzYsAGAc889l3HjxrFx\n40YAlixZwsqVK1m6dCnZ2dkMHjyY22+/ndmzZ+/Utq5pmFJEkllPYIG7LwIws78CA4AvY+p0JdgR\nBHefa2YdzawtUAycDvxHeG4bsK3+Qo/Dm3fBhmVw5VTIbBJ1NCIJJycnh1NOOYVu3brRt29fLrnk\nEk466SQAmjVrxnPPPceCBQu4/fbbSUtLIzMzk9GjRwMwZMgQ+vTpQ/v27TWBX0RkLxwALI55XQic\nUKnOZ8BPgffNrCdwEMGOImVAEfBfZtYd+AS40d03he2GmdllBFvB3eruP1R+czMbAgwBOPDAA2vt\npgCY9ybkPwen3Qq5x9XutUWSyPPP77i/8Y033rjD60MOOYRzzz13p3bDhg1j2LBhdRpbBQ1Tikiq\nGwG0MLN8YBjwKUEilgEcC4x292OATUDFnLPRwMFAHrAMeLSqC7v7WHfv4e492rRpU3sRb14Dr94A\nbbvBGXfU3nVFJBLqGRORZLYE6BDzOjcs287d1wNXAFiwwdw3wCKC3ecL3f2jsOpLhMmYu6+oaG9m\nzwCv1VH8VZt8G2xeDT9/KdjKSkQaNPWMiUgymwl0NrNOZtYIuAiYFFshfGKyUfjyKmC6u6939+XA\nYjM7PDzXm3CumZm1i7nEIKCgLm9iB1+Mh4KX4Yzh0O7oentbEak76hkTkaTl7qVmdj3wFpAOjHP3\nL8xsaHh+DNAFeNbMHPgCuDLmEsOA/wuTtUWEPWjAQ2aWBzjwLXB1fdwPG1fCa7dA+2Pg1Jvr5S1F\npO4pGRORpBYuOzG5UtmYmOMPgMN20TYf6FFF+aW1HGb13OG1m2HbJhg4BtL18S2SLDRMKSLSEHz+\nN5j7WrCe2H5HRB2NiNQiJWMiIolu3RKY/CvocGKw0r6IxGXt2rWMGjWqxu369evH2rVr6yCiqikZ\nExFJZO4waRiUl8DAUZCWHnVEIg3GrpKx0tLS3babPHkyLVq0qKuwdpKUkw6+X72ZVz4tpElmOtmN\n0snKTKdJo5jjzHSyG2XQJCxv0igoS0+zqEMXEdnR7Gdh4TvQ7xHIOSTqaET23BvDYfmc2r3m/kdB\n3xG7PD18+HAWLlxIXl4emZmZZGVl0bJlS+bOncvXX3/NwIEDWbx4McXFxdx4440MGTIEgI4dOzJr\n1iw2btxI3759OfXUU5kxYwYHHHAAEydOpEmT2t3xIimTsW9Wb+KJqfNr3K5RRlqQoO02iYspD79n\nheXbk7tdJH+NM9JIU8InIvH64Tt469fQ6XTocWX19UVkByNGjKCgoID8/Hzee+89zjvvPAoKCujU\nqRMA48aNo1WrVmzZsoXjjz+en/3sZ+Tk5Oxwjfnz5/PCCy/wzDPPcOGFF/Lyyy8zePDgWo0zKZOx\nMw5rw6Lf96O4tIzN28rYsq2M4pLwuCT8Css3l5RRHJZvDutVlFe027S1lFUbt4XXKA3alpRRUuY1\nji0rM217r9wOxzHJ3faEbrfJ3Y7JYnC9dBpnpBGsWykiDVp5OUy8DjAYMBLSNKtEGrjd9GDVl549\ne25PxACeeuopxo8fD8DixYuZP3/+TslYp06dyMvLA+C4447j22+/rfW44krGzKwP8CTBOj1/dvcR\nlc5beL4fsBn4D3efHS6W+LeYqgcD97j7E2Z2H/BLgr3fAO4KH0GvFWlpRnajDLIb1V2+WVJWvj15\nq0jyNm/bMbnbUhKTCG6LSQQrfV+3pYQV64p3SAo3byulvIb5XpoRJm8ZNGmU9uNxZtr2HrogiUv7\n8TimZy9rFz1+2Y2Cc00y08lM1y8FkTr38Vj49n3o/ydoUcv7WoqkqKZNm24/fu+995g6dSoffPAB\n2dnZnHnmmRQXF+/UpnHjH3e5SE9PZ8uWLbUeV7WZipmlAyOBswk22Z1pZpPc/cuYan2BzuHXCQT7\ntp3g7vMI9m6ruM4SYHxMu8fd/ZHauJEoZKankZmeRvOszDq5vruzrayc4m3lbC4p3W0yV1XPXvG2\nHXsDV23cxpaSLTu1q6nMdKu2h27H5C5MDCvm6VXTLkvz9xo8dw+/x5TFnNd/32qsWgBT74PO58Ax\n9b+kmUiyaN68ORs2bKjy3Lp162jZsiXZ2dnMnTuXDz/8sJ6j+1E83UY9gQXuvgjAzP4KDCDcFiQ0\nAPgfDz6BPwy3F2nn7sti6vQGFrr7d7UUe9IzMxpnpNM4I519qbuEr7ikPEzmSsNkrjwYji2pNLy7\nbcdewKqSwh82lQTXiGm3rbS8xnE1ykj7cR5eZvr2uXbbf8nvcBPsVFZVPd9ez3cqq3y8p9epqh7V\n1tvNe8QEVcXlth9WVW/HRGj3MRD3Pe061ngd2X4fXr/htJo1SiXlZTDhmmDPyQueAk07ENljOTk5\nnHLKKXTr1o0mTZrQtm3b7ef69OnDmDFj6NKlC4cffjgnnnhiZHHGk4wdACyOeV1I0PtVXZ0DgNhk\n7CLghUrthpnZZcAs4FZ3/6Hym5vZEGAIwIEHqqu+tpnZ9nlqrZo2qr7BHigr9+3J2k7JXUnp9uSv\nchIX27O3wy982+Hb9vvYuSy+ej9ez2Lq7XS6UpntXGaVW+wqhl2/X1Wx7hBq3G13vka897wnsbLb\nf/8d27Zpro2td6tsG+zfDXoOgX3aVV9fRHbr+eefr7K8cePGvPHGG1Weq5gX1rp1awoKftx69rbb\nbqv1+KCeJvCH+7r1B+6MKR4NPEjwR/aDwKPALyq3dfexwFiAHj161HzGvEQuPc1o1jiDZo2T8nkR\nkdqV2QTOfzzqKESkHsUzE3sJ0CHmdW5YVpM6fYHZ7r6iosDdV7h7mbuXA88QDIeKiIiIpJR4krGZ\nQGcz6xT2cF0ETKpUZxJwmQVOBNZVmi92MZWGKM0stv99EFCAiIiIJBWv6cTSBmhv77HacSN3LzWz\n64G3CJa2GOfuX5jZ0PD8GGAywbIWCwiWtriior2ZNSV4EvPqSpd+yMzyCIYpv63ivIiIiDRgWVlZ\nrF69mpycnKRdA9PdWb16NVlZWXt8jbgm8YTrf02uVDYm5tiBKnevdfdNQE4V5XpeW0REJInl5uZS\nWFhIUVFR9ZUbsKysLHJzc/e4vWZUi4iISJ3IzMzcYcV7qZqWUhcRERGJkJIxkf/f3v28WFWHcRx/\nf6hxVdBihMS0EtzYyiFECsKluHHTwo1Bu4LAltIi/wMXrSLIhSC1KUJCaRW4ShTxZ1JMblKEysAf\nFITwtLiHstvM3DNzOOd7v8/5vODCvXO+A89zP2cevpw7h2tmZlaQN2NmZmZmBammW04l/Qq0/Tql\nReC3HsuZF+4zjzH0COvv88WI2NxXMUNZ5/yCcZwPY+gR3GcmvcyvqjZj6yHpYkS8WrqOvrnPPMbQ\nI4ynz67G8D6NoUdwn5n01aM/pjQzMzMryJsxMzMzs4Iyb8Y+KV3AQNxnHmPoEcbTZ1djeJ/G0CO4\nz0x66THt/4yZmZmZ1SDzlTEzMzOzuefNmJmZmVlB1W/GJO2X9IOkZUlHVzguSR81x69KWipRZ1ct\n+twn6b6ky83jwxJ1diHphKRfJF1f5XiWLGf1mSHLbZK+lfS9pBuSjqywJkWeXXh+/XM8wznv+UWa\nLIefXxFR7QN4CvgJ2AFsAq4Au6bWHADOAgL2AudL191Tn/uAr0vX2rHPN4Al4Poqx6vPsmWfGbLc\nAiw1z58Ffsz4t9nxPfL8+ndNhnPe8ytPloPPr9qvjO0BliPiVkT8BXwOHJxacxA4GRPfAc9J2jJ0\noR216bN6EXEO+H2NJRmybNNn9SLibkRcap4/BG4CW6eWpcizA8+vRDy/8igxv2rfjG0Ffn7i9W3+\n/4a1WTPv2vbwWnO59KykV4YpbVAZsmwrTZaSXgJ2A+enDo0pz5V4fv1XmnN+FRmybCtNlkPNr6c3\n+os2dy4B2yPikaQDwFfAzsI12cakyVLSM8AXwPsR8aB0PTa30pzzlifLIedX7VfG7gDbnnj9QvOz\n9a6ZdzN7iIgHEfGoeX4GWJC0OFyJg8iQ5UxZspS0wGSQnYqIL1dYMoo81+D51chyzs+QIcuZsmQ5\n9PyqfTN2Adgp6WVJm4BDwOmpNaeBt5o7H/YC9yPi7tCFdjSzT0nPS1LzfA+TbO8NXmm/MmQ5U4Ys\nm2K8xAYAAADJSURBVPo/BW5GxPFVlo0izzV4fjUynPMtZMhypgxZlphfVX9MGRGPJb0HfMPkjp0T\nEXFD0jvN8Y+BM0zuelgG/gDeLlXvRrXs803gXUmPgT+BQ9Hc8lELSZ8xuRNnUdJt4BiwAHmyhFZ9\nVp8l8DpwGLgm6XLzsw+A7ZArz43y/PL8KlNpN55f/eTpr0MyMzMzK6j2jynNzMzMqubNmJmZmVlB\n3oyZmZmZFeTNmJmZmVlB3oyZmZmZFeTNmJmZmVlB3oyZmZmZFfQ3P7N8Cxd6ChUAAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0542177a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if args.fit:\n",
    "    plot_logs(train_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-19T12:25:48.820602",
     "start_time": "2017-03-19T12:25:48.755511"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>day_in_cycle</th>\n",
       "      <th>symptom</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.015699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>pms</td>\n",
       "      <td>0.012740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>sad</td>\n",
       "      <td>0.009382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>sensitive_emotion</td>\n",
       "      <td>0.018679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>energized</td>\n",
       "      <td>0.002603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>exhausted</td>\n",
       "      <td>0.007928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>high_energy</td>\n",
       "      <td>0.012371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>low_energy</td>\n",
       "      <td>0.016944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>cramps</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>headache</td>\n",
       "      <td>0.015357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>ovulation_pain</td>\n",
       "      <td>0.004796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>tender_breasts</td>\n",
       "      <td>0.019256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>acne_skin</td>\n",
       "      <td>0.008963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>good_skin</td>\n",
       "      <td>0.007501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>oily_skin</td>\n",
       "      <td>0.006092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>dry_skin</td>\n",
       "      <td>0.003571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.015705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>pms</td>\n",
       "      <td>0.012742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>sad</td>\n",
       "      <td>0.009384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>sensitive_emotion</td>\n",
       "      <td>0.018685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>energized</td>\n",
       "      <td>0.002604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>exhausted</td>\n",
       "      <td>0.007930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>high_energy</td>\n",
       "      <td>0.012376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>low_energy</td>\n",
       "      <td>0.016945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>cramps</td>\n",
       "      <td>0.025401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>headache</td>\n",
       "      <td>0.015360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>ovulation_pain</td>\n",
       "      <td>0.004796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>tender_breasts</td>\n",
       "      <td>0.019262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>acne_skin</td>\n",
       "      <td>0.008965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>good_skin</td>\n",
       "      <td>0.007503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>33</td>\n",
       "      <td>sad</td>\n",
       "      <td>0.009384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>33</td>\n",
       "      <td>sensitive_emotion</td>\n",
       "      <td>0.018686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>33</td>\n",
       "      <td>energized</td>\n",
       "      <td>0.002604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>33</td>\n",
       "      <td>exhausted</td>\n",
       "      <td>0.007930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>33</td>\n",
       "      <td>high_energy</td>\n",
       "      <td>0.012377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>33</td>\n",
       "      <td>low_energy</td>\n",
       "      <td>0.016946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>33</td>\n",
       "      <td>cramps</td>\n",
       "      <td>0.025401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>33</td>\n",
       "      <td>headache</td>\n",
       "      <td>0.015361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>33</td>\n",
       "      <td>ovulation_pain</td>\n",
       "      <td>0.004796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>33</td>\n",
       "      <td>tender_breasts</td>\n",
       "      <td>0.019264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>33</td>\n",
       "      <td>acne_skin</td>\n",
       "      <td>0.008965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>33</td>\n",
       "      <td>good_skin</td>\n",
       "      <td>0.007503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>33</td>\n",
       "      <td>oily_skin</td>\n",
       "      <td>0.006094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>33</td>\n",
       "      <td>dry_skin</td>\n",
       "      <td>0.003572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>34</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.015705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>34</td>\n",
       "      <td>pms</td>\n",
       "      <td>0.012743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>34</td>\n",
       "      <td>sad</td>\n",
       "      <td>0.009384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>34</td>\n",
       "      <td>sensitive_emotion</td>\n",
       "      <td>0.018686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>34</td>\n",
       "      <td>energized</td>\n",
       "      <td>0.002604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>34</td>\n",
       "      <td>exhausted</td>\n",
       "      <td>0.007930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>34</td>\n",
       "      <td>high_energy</td>\n",
       "      <td>0.012377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>34</td>\n",
       "      <td>low_energy</td>\n",
       "      <td>0.016946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>34</td>\n",
       "      <td>cramps</td>\n",
       "      <td>0.025401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>34</td>\n",
       "      <td>headache</td>\n",
       "      <td>0.015361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>34</td>\n",
       "      <td>ovulation_pain</td>\n",
       "      <td>0.004796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>34</td>\n",
       "      <td>tender_breasts</td>\n",
       "      <td>0.019264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>34</td>\n",
       "      <td>acne_skin</td>\n",
       "      <td>0.008965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>34</td>\n",
       "      <td>good_skin</td>\n",
       "      <td>0.007503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>34</td>\n",
       "      <td>oily_skin</td>\n",
       "      <td>0.006094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>34</td>\n",
       "      <td>dry_skin</td>\n",
       "      <td>0.003572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   user_id  day_in_cycle            symptom  \\\n",
       "0     03009100-a1fa-4fad-bf9b-6102c690f3be             1              happy   \n",
       "1     03009100-a1fa-4fad-bf9b-6102c690f3be             1                pms   \n",
       "2     03009100-a1fa-4fad-bf9b-6102c690f3be             1                sad   \n",
       "3     03009100-a1fa-4fad-bf9b-6102c690f3be             1  sensitive_emotion   \n",
       "4     03009100-a1fa-4fad-bf9b-6102c690f3be             1          energized   \n",
       "5     03009100-a1fa-4fad-bf9b-6102c690f3be             1          exhausted   \n",
       "6     03009100-a1fa-4fad-bf9b-6102c690f3be             1        high_energy   \n",
       "7     03009100-a1fa-4fad-bf9b-6102c690f3be             1         low_energy   \n",
       "8     03009100-a1fa-4fad-bf9b-6102c690f3be             1             cramps   \n",
       "9     03009100-a1fa-4fad-bf9b-6102c690f3be             1           headache   \n",
       "10    03009100-a1fa-4fad-bf9b-6102c690f3be             1     ovulation_pain   \n",
       "11    03009100-a1fa-4fad-bf9b-6102c690f3be             1     tender_breasts   \n",
       "12    03009100-a1fa-4fad-bf9b-6102c690f3be             1          acne_skin   \n",
       "13    03009100-a1fa-4fad-bf9b-6102c690f3be             1          good_skin   \n",
       "14    03009100-a1fa-4fad-bf9b-6102c690f3be             1          oily_skin   \n",
       "15    03009100-a1fa-4fad-bf9b-6102c690f3be             1           dry_skin   \n",
       "16    03009100-a1fa-4fad-bf9b-6102c690f3be             2              happy   \n",
       "17    03009100-a1fa-4fad-bf9b-6102c690f3be             2                pms   \n",
       "18    03009100-a1fa-4fad-bf9b-6102c690f3be             2                sad   \n",
       "19    03009100-a1fa-4fad-bf9b-6102c690f3be             2  sensitive_emotion   \n",
       "20    03009100-a1fa-4fad-bf9b-6102c690f3be             2          energized   \n",
       "21    03009100-a1fa-4fad-bf9b-6102c690f3be             2          exhausted   \n",
       "22    03009100-a1fa-4fad-bf9b-6102c690f3be             2        high_energy   \n",
       "23    03009100-a1fa-4fad-bf9b-6102c690f3be             2         low_energy   \n",
       "24    03009100-a1fa-4fad-bf9b-6102c690f3be             2             cramps   \n",
       "25    03009100-a1fa-4fad-bf9b-6102c690f3be             2           headache   \n",
       "26    03009100-a1fa-4fad-bf9b-6102c690f3be             2     ovulation_pain   \n",
       "27    03009100-a1fa-4fad-bf9b-6102c690f3be             2     tender_breasts   \n",
       "28    03009100-a1fa-4fad-bf9b-6102c690f3be             2          acne_skin   \n",
       "29    03009100-a1fa-4fad-bf9b-6102c690f3be             2          good_skin   \n",
       "...                                    ...           ...                ...   \n",
       "1570  9f13e16f-c845-4d69-8875-e79f3442c45c            33                sad   \n",
       "1571  9f13e16f-c845-4d69-8875-e79f3442c45c            33  sensitive_emotion   \n",
       "1572  9f13e16f-c845-4d69-8875-e79f3442c45c            33          energized   \n",
       "1573  9f13e16f-c845-4d69-8875-e79f3442c45c            33          exhausted   \n",
       "1574  9f13e16f-c845-4d69-8875-e79f3442c45c            33        high_energy   \n",
       "1575  9f13e16f-c845-4d69-8875-e79f3442c45c            33         low_energy   \n",
       "1576  9f13e16f-c845-4d69-8875-e79f3442c45c            33             cramps   \n",
       "1577  9f13e16f-c845-4d69-8875-e79f3442c45c            33           headache   \n",
       "1578  9f13e16f-c845-4d69-8875-e79f3442c45c            33     ovulation_pain   \n",
       "1579  9f13e16f-c845-4d69-8875-e79f3442c45c            33     tender_breasts   \n",
       "1580  9f13e16f-c845-4d69-8875-e79f3442c45c            33          acne_skin   \n",
       "1581  9f13e16f-c845-4d69-8875-e79f3442c45c            33          good_skin   \n",
       "1582  9f13e16f-c845-4d69-8875-e79f3442c45c            33          oily_skin   \n",
       "1583  9f13e16f-c845-4d69-8875-e79f3442c45c            33           dry_skin   \n",
       "1584  9f13e16f-c845-4d69-8875-e79f3442c45c            34              happy   \n",
       "1585  9f13e16f-c845-4d69-8875-e79f3442c45c            34                pms   \n",
       "1586  9f13e16f-c845-4d69-8875-e79f3442c45c            34                sad   \n",
       "1587  9f13e16f-c845-4d69-8875-e79f3442c45c            34  sensitive_emotion   \n",
       "1588  9f13e16f-c845-4d69-8875-e79f3442c45c            34          energized   \n",
       "1589  9f13e16f-c845-4d69-8875-e79f3442c45c            34          exhausted   \n",
       "1590  9f13e16f-c845-4d69-8875-e79f3442c45c            34        high_energy   \n",
       "1591  9f13e16f-c845-4d69-8875-e79f3442c45c            34         low_energy   \n",
       "1592  9f13e16f-c845-4d69-8875-e79f3442c45c            34             cramps   \n",
       "1593  9f13e16f-c845-4d69-8875-e79f3442c45c            34           headache   \n",
       "1594  9f13e16f-c845-4d69-8875-e79f3442c45c            34     ovulation_pain   \n",
       "1595  9f13e16f-c845-4d69-8875-e79f3442c45c            34     tender_breasts   \n",
       "1596  9f13e16f-c845-4d69-8875-e79f3442c45c            34          acne_skin   \n",
       "1597  9f13e16f-c845-4d69-8875-e79f3442c45c            34          good_skin   \n",
       "1598  9f13e16f-c845-4d69-8875-e79f3442c45c            34          oily_skin   \n",
       "1599  9f13e16f-c845-4d69-8875-e79f3442c45c            34           dry_skin   \n",
       "\n",
       "      probability  \n",
       "0        0.015699  \n",
       "1        0.012740  \n",
       "2        0.009382  \n",
       "3        0.018679  \n",
       "4        0.002603  \n",
       "5        0.007928  \n",
       "6        0.012371  \n",
       "7        0.016944  \n",
       "8        0.025391  \n",
       "9        0.015357  \n",
       "10       0.004796  \n",
       "11       0.019256  \n",
       "12       0.008963  \n",
       "13       0.007501  \n",
       "14       0.006092  \n",
       "15       0.003571  \n",
       "16       0.015705  \n",
       "17       0.012742  \n",
       "18       0.009384  \n",
       "19       0.018685  \n",
       "20       0.002604  \n",
       "21       0.007930  \n",
       "22       0.012376  \n",
       "23       0.016945  \n",
       "24       0.025401  \n",
       "25       0.015360  \n",
       "26       0.004796  \n",
       "27       0.019262  \n",
       "28       0.008965  \n",
       "29       0.007503  \n",
       "...           ...  \n",
       "1570     0.009384  \n",
       "1571     0.018686  \n",
       "1572     0.002604  \n",
       "1573     0.007930  \n",
       "1574     0.012377  \n",
       "1575     0.016946  \n",
       "1576     0.025401  \n",
       "1577     0.015361  \n",
       "1578     0.004796  \n",
       "1579     0.019264  \n",
       "1580     0.008965  \n",
       "1581     0.007503  \n",
       "1582     0.006094  \n",
       "1583     0.003572  \n",
       "1584     0.015705  \n",
       "1585     0.012743  \n",
       "1586     0.009384  \n",
       "1587     0.018686  \n",
       "1588     0.002604  \n",
       "1589     0.007930  \n",
       "1590     0.012377  \n",
       "1591     0.016946  \n",
       "1592     0.025401  \n",
       "1593     0.015361  \n",
       "1594     0.004796  \n",
       "1595     0.019264  \n",
       "1596     0.008965  \n",
       "1597     0.007503  \n",
       "1598     0.006094  \n",
       "1599     0.003572  \n",
       "\n",
       "[1600 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
