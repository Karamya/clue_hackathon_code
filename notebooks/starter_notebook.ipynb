{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-03-18T19:27:38.709Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-03-18T19:27:39.139Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run ../prepare_data.py -N_users 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['299fd10f-c090-4162-8b7a-6c54437c98eb']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_of_users = get_sample_of_users(1)\n",
    "sample_of_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-18T18:23:18.078679",
     "start_time": "2017-03-18T18:23:17.687893"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sequence = transform_users(sample_of_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.,    0.,    0., ...,    0.,    0.,    1.],\n",
       "       [   0.,    0.,    0., ...,    0.,    0.,    2.],\n",
       "       [   0.,    0.,    0., ...,    0.,    0.,    3.],\n",
       "       ..., \n",
       "       [   0.,    0.,    0., ...,    0.,    0.,  320.],\n",
       "       [   0.,    0.,    0., ...,    0.,    0.,  321.],\n",
       "       [   0.,    0.,    0., ...,    0.,    0.,  322.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(322, 82)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>322.000000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>322.0</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>322.0</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>322.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>322.0</td>\n",
       "      <td>322.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.012422</td>\n",
       "      <td>0.027950</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018634</td>\n",
       "      <td>0.040373</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015528</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.110934</td>\n",
       "      <td>0.165087</td>\n",
       "      <td>0.078688</td>\n",
       "      <td>0.146057</td>\n",
       "      <td>0.078688</td>\n",
       "      <td>0.146057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135437</td>\n",
       "      <td>0.197138</td>\n",
       "      <td>0.078688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.097619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>241.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>322.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  322.000000  322.000000  322.000000  322.000000  322.000000  322.000000   \n",
       "mean     0.012422    0.027950    0.006211    0.021739    0.006211    0.021739   \n",
       "std      0.110934    0.165087    0.078688    0.146057    0.078688    0.146057   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "          6           7           8           9      ...              72  \\\n",
       "count  322.0  322.000000  322.000000  322.000000     ...      322.000000   \n",
       "mean     0.0    0.018634    0.040373    0.006211     ...        0.006211   \n",
       "std      0.0    0.135437    0.197138    0.078688     ...        0.078688   \n",
       "min      0.0    0.000000    0.000000    0.000000     ...        0.000000   \n",
       "25%      0.0    0.000000    0.000000    0.000000     ...        0.000000   \n",
       "50%      0.0    0.000000    0.000000    0.000000     ...        0.000000   \n",
       "75%      0.0    0.000000    0.000000    0.000000     ...        0.000000   \n",
       "max      0.0    1.000000    1.000000    1.000000     ...        1.000000   \n",
       "\n",
       "          73          74     75     76     77     78          79     80  \\\n",
       "count  322.0  322.000000  322.0  322.0  322.0  322.0  322.000000  322.0   \n",
       "mean     0.0    0.003106    0.0    0.0    0.0    0.0    0.015528    0.0   \n",
       "std      0.0    0.055728    0.0    0.0    0.0    0.0    0.123832    0.0   \n",
       "min      0.0    0.000000    0.0    0.0    0.0    0.0    0.000000    0.0   \n",
       "25%      0.0    0.000000    0.0    0.0    0.0    0.0    0.000000    0.0   \n",
       "50%      0.0    0.000000    0.0    0.0    0.0    0.0    0.000000    0.0   \n",
       "75%      0.0    0.000000    0.0    0.0    0.0    0.0    0.000000    0.0   \n",
       "max      0.0    1.000000    0.0    0.0    0.0    0.0    1.000000    0.0   \n",
       "\n",
       "               81  \n",
       "count  322.000000  \n",
       "mean   161.500000  \n",
       "std     93.097619  \n",
       "min      1.000000  \n",
       "25%     81.250000  \n",
       "50%    161.500000  \n",
       "75%    241.750000  \n",
       "max    322.000000  \n",
       "\n",
       "[8 rows x 82 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = df.loc[:, :15]\n",
    "df3 = pd.Series(df.loc[:,81])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.columns = [\n",
    "    'happy', 'pms', 'sad', 'sensitive_emotion',\n",
    "    'energized', 'exhausted', 'high_energy', 'low_energy',\n",
    "    'cramps', 'headache', 'ovulation_pain', 'tender_breasts',\n",
    "    'acne_skin', 'good_skin', 'oily_skin', 'dry_skin'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>happy</th>\n",
       "      <th>pms</th>\n",
       "      <th>sad</th>\n",
       "      <th>sensitive_emotion</th>\n",
       "      <th>energized</th>\n",
       "      <th>exhausted</th>\n",
       "      <th>high_energy</th>\n",
       "      <th>low_energy</th>\n",
       "      <th>cramps</th>\n",
       "      <th>headache</th>\n",
       "      <th>ovulation_pain</th>\n",
       "      <th>tender_breasts</th>\n",
       "      <th>acne_skin</th>\n",
       "      <th>good_skin</th>\n",
       "      <th>oily_skin</th>\n",
       "      <th>dry_skin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>322.000000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>322.0</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>322.0</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>322.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.012422</td>\n",
       "      <td>0.027950</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018634</td>\n",
       "      <td>0.040373</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>0.018634</td>\n",
       "      <td>0.003106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.110934</td>\n",
       "      <td>0.165087</td>\n",
       "      <td>0.078688</td>\n",
       "      <td>0.146057</td>\n",
       "      <td>0.078688</td>\n",
       "      <td>0.146057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135437</td>\n",
       "      <td>0.197138</td>\n",
       "      <td>0.078688</td>\n",
       "      <td>0.078688</td>\n",
       "      <td>0.135437</td>\n",
       "      <td>0.055728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078688</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            happy         pms         sad  sensitive_emotion   energized  \\\n",
       "count  322.000000  322.000000  322.000000         322.000000  322.000000   \n",
       "mean     0.012422    0.027950    0.006211           0.021739    0.006211   \n",
       "std      0.110934    0.165087    0.078688           0.146057    0.078688   \n",
       "min      0.000000    0.000000    0.000000           0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000           0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000           0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000           0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000           1.000000    1.000000   \n",
       "\n",
       "        exhausted  high_energy  low_energy      cramps    headache  \\\n",
       "count  322.000000        322.0  322.000000  322.000000  322.000000   \n",
       "mean     0.021739          0.0    0.018634    0.040373    0.006211   \n",
       "std      0.146057          0.0    0.135437    0.197138    0.078688   \n",
       "min      0.000000          0.0    0.000000    0.000000    0.000000   \n",
       "25%      0.000000          0.0    0.000000    0.000000    0.000000   \n",
       "50%      0.000000          0.0    0.000000    0.000000    0.000000   \n",
       "75%      0.000000          0.0    0.000000    0.000000    0.000000   \n",
       "max      1.000000          0.0    1.000000    1.000000    1.000000   \n",
       "\n",
       "       ovulation_pain  tender_breasts   acne_skin  good_skin   oily_skin  \\\n",
       "count      322.000000      322.000000  322.000000      322.0  322.000000   \n",
       "mean         0.006211        0.018634    0.003106        0.0    0.006211   \n",
       "std          0.078688        0.135437    0.055728        0.0    0.078688   \n",
       "min          0.000000        0.000000    0.000000        0.0    0.000000   \n",
       "25%          0.000000        0.000000    0.000000        0.0    0.000000   \n",
       "50%          0.000000        0.000000    0.000000        0.0    0.000000   \n",
       "75%          0.000000        0.000000    0.000000        0.0    0.000000   \n",
       "max          1.000000        1.000000    1.000000        0.0    1.000000   \n",
       "\n",
       "       dry_skin  \n",
       "count     322.0  \n",
       "mean        0.0  \n",
       "std         0.0  \n",
       "min         0.0  \n",
       "25%         0.0  \n",
       "50%         0.0  \n",
       "75%         0.0  \n",
       "max         0.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4ee990def0>]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztnW2wXVV5x//PvQFshYqYW8QQJLaxbepb6RVsh7Z0OkiC\nH1JnOi3oVMvoZJiCtR+ciuPU2vFDxzraDiOSUsv4UgdmqrTGTlrUFqWtg3KjEAg0eEWEBDQXsCgg\nhJvz9MPZr+eevfdJstde61nr/5vJnJe9s9ez9l3rOWs/b0tUFYQQQuJizrcAhBBC+ofKnRBCIoTK\nnRBCIoTKnRBCIoTKnRBCIoTKnRBCIoTKnRBCIoTKnRBCIoTKnRBCImSdr4bXr1+vZ599tq/mCSHE\nJHv27HlUVRe6zvOm3M8++2wsLS35ap4QQkwiIt+b5TyaZQghJEKo3AkhJEKo3AkhJEKo3AkhJEKo\n3AkhJEI6lbuIXC8ih0Tk7objIiJXi8iyiOwVkXP6F5MQQsjRMMvK/RMAtrYc3wZgc/ZvB4Brj18s\nQgghx0OnclfVWwE83nLKdgCf0jG3AThVRM7oS8AmfvjUYey+6xHXzXjlwA+fxi37D/kWgyTOEz95\nDl+48+Her/vAo0/hf5YfbTz+xX3fx6EfP9N7u13cffAJfOSL+/H1+x8bvO0+6cPmvgHAQ5XPB7Lv\n1iAiO0RkSUSWVlZWjqvRXXc+jD/+zDfx42eeO67rhMynb/se/uSGb/kWgyTO7rsewTtu+BYee/LZ\nXq/78f++H+/6pzunHls9MsLl/7gHn91zoNc2Z+Har3wHV//nMj508/7B2+6TQR2qqnqdqi6q6uLC\nQmf2bCvPHRkBAI6M4t3ge/WIYvVIvP0jNlh1NNdWjyieaxjfIx3/8zH+V0ej7NX23OtDuR8EsLHy\n+czsO6dodt+N3/9WRqoYacQdJCYYOZprI1Vow/jOx72P8Z/3s0k2K/Sh3HcBeEsWNfM6AE+oqnNj\nuGJ8463/AdpQBeLtHbFCPse059E4y/j2Mb3zNq3Pvc7CYSJyA4ALAKwXkQMA/gLACQCgqjsB7AZw\nMYBlAE8DuMyVsFVi+QN0En0HSejkQ7BvRatoXpz5nd/5wtFL473RqdxV9dKO4wrgit4kmhFXAy4k\nVLX31RIhR4srRdu2ci/GvYcJXvbX9twzm6Ga2+JiNsvkTiVCfFLYv3sejKraeE1Xdv5ZKPs7fNt9\nYla5p2CWUTQ7nAixjqJl5e7Izj8LOvFqFbPKPSdm3UeHKgkBdWQh0ZYB7tPsWvbX9uwzq9x9/rIP\nxdjh5FsKkjpFZFrf0TJoW7mX5wxNLFPOsHKvv8ZILCsIYht3K/eWse1xfhcLR+PTzqxyLx0uxv8C\nLcQyyIhtXM21cZJe8zHAz8JGI9EtZpV7mcTkWRCHpOA0JuFTmmX6vm6zqcenU9NVf4fGrnK3fudn\nIIUsXBI+zkyg2nxNDWDlbn3e2VXu+avt+98KV+4kLPp2qDa7aIOIlhm+6V6xq9w9FhYaihT8CiR8\n8kSj3guHjZpXx2XhsH7bnIVRJL4uw8o9e/UrhlNS8CuQ8HG1ih4n6bU36jWJyfjEs6vcU7BHR9w1\nYgdXtVbaa8vU2x6USBaOdpV7JH+ANlLwK5DwcfUEOU7Sa4iW8TjmY3liNqvcy4L6fuVwSQp+BRI+\nrnw/46qnDcfgb+yPHD2pDI1Z5Z6CWWaUwNMJMYAjB6O2hEL6XLwViypWhfREAoovFscOsY2r0dc2\nvkOoCmkds8o9BXt0OcAJ8YfTqpAN1/VZO4pJTJ5JpSokEPcPGAkfl1Uhq69t5wyJz9IHfWJWuRdO\nHuN2sTZ8pmATkuNqV6Q2R63fwmFxBDKYVe6x7HPYRgpljUn4uDJThG+WGb7tPrGr3COJRW0jhVh+\nEj6uqyROW6D5NEmyKqRnYlbqOSmEexIDOHOoNl/Xa7QMV+5+SWEji3LTAL9ykLRxZf9us2lrcU6v\nTc5E2abtiWdXuWev1p0ebcSSKUds48o82Lbjkc/FW+lQHb7tPrGr3JOwRyfRSRI4ruzfbX6zEAIm\nrJtD7Sr3BOzRafyAkdBxFy2TvU47tubNcMQy78wq9xTqrqRgeiLh42rjjLYfDZ+bVHOzDs/EkiLc\nRiyDjMRB/xmqzT8axdjvtcXZiGVRZVa5o8VeFwuxPB4S26ijgVjM3eCSmOKYeGaVeyT3v5XSkRVz\nL0notOjgnq47LYnJ/8rd+qybSbmLyFYR2S8iyyJy1ZTjLxCRL4jInSKyT0Qu61/UOrEkGrSRQiw/\nCR+/VSG9pKj6a7tHOpW7iMwDuAbANgBbAFwqIlsmTrsCwD2q+moAFwD4sIic2LOsNXwWFhqaBLpI\nAqZ0qPadxDR+bbuqj7Hv097fJ7Os3M8FsKyq96vqYQA3Atg+cY4COEVEBMDJAB4HsNqrpFMaBOwn\nGrRRDrKIO0mCx7VZprUqpMfNOlJwqG4A8FDl84HsuyofBfBLAB4GcBeAd6qq02K8ISQ5uCYF0xMJ\nH2cmElaFdEpfDtWLANwB4CUAXgPgoyLyM5MnicgOEVkSkaWVlZXjarBQ6sb/AG2k4DQmFnBjpmh3\nqGavXkzu6ZhlDgLYWPl8ZvZdlcsA3KRjlgF8F8AvTl5IVa9T1UVVXVxYWDhWmbNrZa/HdZWw8bkD\nPCE5+YY4zgqHTV25+xv7xQZAxqfdLMr9dgCbRWRT5iS9BMCuiXMeBPA7ACAipwP4BQD39ynoJLHs\nltKGzx3gCclxtXdCW9XTEDLQreuWdV0nqOqqiFwJ4GYA8wCuV9V9InJ5dnwngA8A+ISI3AVAALxb\nVR91KHca+4vqmjeEDI67UMjstaW6jM8kJuuzrlO5A4Cq7gawe+K7nZX3DwN4fb+idcmUvQ7Z6MCk\nsNsUCR/nSUwtDlUfMzyW5EGzGaopxLlzsw4SAq7i3NtWyD5DnVOKcw+SFMwyjHMnQeDYLDOaosHz\n73ws3hgK6ZsU4tzz13i7SAygU971c93m67kyBc1CtU3LlgGzyj0Fe3QsKwhiG1c1jtrGdwhJTL7a\n7wu7yj0BxdeW5EHIUDh3qAZWFdLds8qwmFXusTg9WmFVSBIAuUm8/8JhLeO7WLx5SGKqrdztTj6z\nyt3nNlxDwSQmEgLOSk+3zGGfY7+q0C1HqtlV7vmr4ZvfRfloGnEnSfC4N8tMO+Zv7Nccqobnnl3l\nnkD2Zgp+BWIARyaS2Tbr6LXJmaBD1TMp7FKUgumJhI+rjdpHLQu0MonJh809jvlmV7lnr5ZtYl0k\n4TQmweNq74Sy6unaY65+UGai0qZlRW9XuSeUvWl4fJEIcF0VsjVapt8mZ6KexORBgJ6wq9zzV8M3\nv4sU/AokfHxUhfS5GU/Vt2B55plV7iHUe3ZNClm4JHxclwJodaj6jpYxPPnMKvfSoWr35nfBqpAk\nBFxtjNNmV/c59keqmJ+TsRzDN98bZpV7TsS6PYmyxiR81NHSvS0azOfYVwXmJVPuo46TA8ascvf5\n2DYUrh+HCZmFchy6iZZpb3N4FECm203rF7vKPQV7NJOYSACkVhUSCszlK3fDc8+sci93ZPcrh0vK\niKCIO0mCpywc5ua67Xuo+klios3dI2UChOXb3w6TmEgIuDLLoJjDa4/4jIZTAJluN61f7Cr3FEIh\naZYhAeDeLDMlzt3j2FdVzM3RLOONFPJ7WBWShISbdfv06/quClnY3A3PPbvKPYHyA4xzJyHgKixx\npjh3D6GIWnGoWlYvhpV7/TVG2h5bCRkK1+UHpmlQX6GQ+Vybs6/bDSv37DXmVa3SoUoCwNUio8x8\nbT429MImby6PlqFD1QNJmGXWvCFkeFxtVl2G+k455mnM580yzt0jbQMjFlLIwiXh48wE2hYt4ylJ\nMZclApO7XeWeUlVIH04lQnJc7QjWlsfhaxeyXK8USUyGV49mlTs82eSGJIUfMBI+rp4cS7/Z2uv7\nGvt5X+dplvFHUmaZmDtJgsd5tEyADtXCLGN46tlV7kkoPkbLEP+4Kj/Q5qj1FQqZk0wSk4hsFZH9\nIrIsIlc1nHOBiNwhIvtE5Kv9irmWFOqupPEDRkInn2vOCoe1aPehh37e1/kIyg+s6zpBROYBXAPg\nQgAHANwuIrtU9Z7KOacC+BiArar6oIj8rCuBc5JIYspfI+4jCR/n0TIte6j6M8ukURXyXADLqnq/\nqh4GcCOA7RPnvAnATar6IACo6qF+xVxLmzMmFlJ4OiHh49osE1JVyLy9+blcDruzbxblvgHAQ5XP\nB7LvqrwcwAtF5CsiskdE3jLtQiKyQ0SWRGRpZWXl2CTOSMFUkcLTCTFAQlUhy/ID9s0yfTlU1wH4\nVQBvAHARgD8XkZdPnqSq16nqoqouLiwsHFeDKSg+VxsTE3I0jFqU8PFdt82h6mfs530tCocZfm7u\ntLkDOAhgY+Xzmdl3VQ4AeExVnwLwlIjcCuDVAO7rRcoppFAO13fEACGAu2xRXfOmcszX4q1Q7p7a\n75FZVu63A9gsIptE5EQAlwDYNXHO5wGcLyLrROSnAZwH4N5+Ra2TQjlcRsuQEHC1MU5bFqqvMV8k\nMRWFw7yI0QudK3dVXRWRKwHcDGAewPWquk9ELs+O71TVe0Xk3wHsBTAC8HFVvdul4ClEklCpkxBw\nvYqeWjisOOY7WsbuHJzFLANV3Q1g98R3Oyc+fwjAh/oTrVOm8avhm99FCj9gJHxcRMtUlfZUm7vn\naJlUzDJBkoZDdfxKhyrxSVvd9WOleq3p0TK+HKrxJDHZVe6+BRgAX2VPCamiDh4hO1fu/Tc5E3l7\nyZQfCJHil92yx6MDVoUkIeBis47qtaat3H1XhWScu0eSCBNktAwJABcm0Oq1pu/E5OmpNbFQyCBp\n2zk9FmiWISEwcmD/HnWYZYpjvjfrMLx8NKvcU9iCLoU+kvBx/ZTctoeqL7OM0CzjjxSSmFJ4OiEG\ncGyWmb4TUz72/cS55zsxWY5UM6vcCwzf/C6S8CuQ4HES5165Vmu0TG8tzkYR5z7np/0+MavcUyiH\nm0IsPwkfdWAjqTtUp8W5rz1vCFgVMgBSUnyWHw2JfXLTpyuH6jR8VYWcjHO3vHy0q9wjrwrZleRB\nyFC4iNqqx7lPOe7JLlPY3Jmh6o/YHaqjrtFPyEC4iFzpcqiqJ7NrGS0z/mxZv9hV7vmr4ZvfBlfu\nJBScmEA7k5jyV79mGcsJhHaVe+RVIau9irnEAgkfF0W8upKYtDivtyZnoigclsgG2UHiyyY3FLVo\nAn9iEOJk/NWtji3RMgOP/jWhkIYnn13lnr3GGklSW9nE2UViBBcmEu0Y374S+GiWCQBvhYU8kEAX\nScA4rwo55cr+Hswn4twHb78/zCr32MvhdiV5EDIUruPcp17WU/mBNYXDDE89s8o99pV7LT070j4S\nGziPlmk57Mssk4dCWg7YsKvci1e7N7+NukM1zj4SKzg2y7SFQvbY5izkc22e5Qc8Enn5ATpUSSi4\n3qwjxKqQc3OsCukNX3/8odCG94QMjYt0umCrQk5Gywzcfp+YVe6Rh7l3rmwIGYpiJ6ZRn9esfAio\nKmTe1zn7dcMMK/fIzTJd6dmEDIWLhKKu8hr1gILhJ0C5crc7+ewqd08lQYci1n4Re7iITKs9mU6p\nMaCeFjdrbO49Pq0MjV3lHnuce/U9FT3xiGsT6PQwdxeW/m7yReNcEQppF/vK3fLdb6E6uFk3jPik\nLK89XBKTL59TkcTE8gP+0Mhdql1xwIQMhfNt9qYdbzjXNcU2e3OMlvFG/Cv3ynvTQ4xYx8Uyqsvs\n6Gv85y1xD1WP5Pc8VsdjV9U8QobCZ1XIpuOuKOPc8892J99Myl1EtorIfhFZFpGrWs57rYisisjv\n9SfidHyVBB0KOlRJKBRx7j0Ow9FRrMx9mGXmUzDLiMg8gGsAbAOwBcClIrKl4bwPAvhi30JOI/po\nmQ6bJCFD4ca71eVQrUbLDG+WkUTMMucCWFbV+1X1MIAbAWyfct47AHwOwKEe5evE8s1vg1UhSTA4\nMcusufy0Jtec65o1ZhnDS6tZlPsGAA9VPh/IvisQkQ0A3gjg2v5Ea6Zur7N789s4msdWQlzierOO\ntsJhfbfbxaRZxnIYcl8O1b8F8G5Vbc3nEpEdIrIkIksrKyvH3FgKJgs6VEkoFOPPVShkR5z7kAu4\ntWYZu5Nv3QznHASwsfL5zOy7KosAbsxuyHoAF4vIqqr+S/UkVb0OwHUAsLi4eMx3bZTAyr2exOFP\nDkJKh6qbJKZp1Ff2vTXbSS5XnsRkmVmU++0ANovIJoyV+iUA3lQ9QVU35e9F5BMA/nVSsfeJNryP\nFZpliE+KhbuzlXt7nPvA9QcAVEMhB2y7ZzqVu6quisiVAG4GMA/gelXdJyKXZ8d3OpZxikzl+1hX\ntaMUbE/EBE6qQlauNW0O+46WiWGzjllW7lDV3QB2T3w3Vamr6h8dv1gd8nguBzoE1O0kBFz5fo7O\n5t5fu12s2azD8OQzmaGaguKr2RxjfTwhwePqKbmrvEB9ZT/c+C9s7nO5HHYxr9xN3/0WfJU8JaSK\ntnw6vut2JTG5aLWbwiwTQbSMTeVe23/R7s1vw1cSByFVBjHLTDvecK5r8v4K91D1Q30XF39yuMSX\nQ4mQKq4ekuvKuyuJaXiHKuu5e8LXH35IfDmUCKlSnWtDbtbhaw9hnbS5G557JpV7CiaLrpUNIUPg\napHR7VB1024XeVs0y3giiWiZBPpIbNHvOOxyqHoyyzAU0jMd2W0x4GuzAkKquKrx0hViOXL0xNBF\nYXOfy+WwO/lMKvcUyuFymz0SAq7GXt1R22GWcSLBdBgt45lRAiaLrvRsQoZgVFth9+hQ7ZjE1aeE\nIZP48qaKwmGGV48mlXsK9dwZLUNCwFmce8P7tu+GYdzyHFfufkggQXWCNHpJwsNV1EqnLd9bKOT4\nNYaqkDaVe4czJgboUCUh4Mr302V29J3EFENVSKPKPS2zjOUBRmxTs307W7m3H/eyWcccQyG9YPh+\nz0wKiVokfFwV6TuaqpCDbrM3aZYZrOX+sancE3A2siokCYGukMVjv25XEtN0GVyTtxXDHqo2lbun\nWs9D4iuJg5Aqw2zWsfbC3pKYJvZQtTz3TCr3NBSfH4cSIVVcRaZ1X9dvTFxhczc890wq9xTK4aZg\neiLh46sqpG+HagQ5TFaV+/T3MVF3qEbaSRI+ruZap0PVUbsdrCkcNlzTvWNSuVexfPPbYFVIEgLu\nzDJdK3dPce6Tyt3w5DOp3F1VqgsJJjGREFBHS2hWhXSPSeWeguJjEhMJgbrNvc/rVj+1m2WGHP95\nW/nK3TImlbtfP/ow1DcBJ8QPzuLcOx2qnhZwa8wydmefTeWeQPmBJH7BSPAMUhUyoPGd/4DR5u6J\n+iObNzGcUi93HWknSfAMsYfqNLOLL9Nr4VAtbO7Dtd03NpV7Aqn5tSzckUdBSNK48v10zWFfPqdi\nsw4mMfnBlQc/JLjNHgmBQbbZ60hiGtbkTrOMV1IwRyfw+0UMMIRZJsSqkHmsjOWpZ1O5p5ChmoDp\niYSPs2gZtC/NQ6gKKQLTCsakcndV7yIkUvgBI+EzRFXIaXPY2/iv1JYRJOBQFZGtIrJfRJZF5Kop\nx98sIntF5C4R+ZqIvLp/UUtSUHy+HksJqTLqUMLHft0Oh6qn8Z/3VzBevVv2d3UqdxGZB3ANgG0A\ntgC4VES2TJz2XQC/paqvBPABANf1LWiVFBJ8WFuGhIH7uRaUQ7VYuQuMW2VmWrmfC2BZVe9X1cMA\nbgSwvXqCqn5NVX+YfbwNwJn9ilmncHpIvKvaFPpIwqc6Dl1ssyfStHL3U3a3sLljHDFjeebNotw3\nAHio8vlA9l0TbwPwb9MOiMgOEVkSkaWVlZXZpWxgTsT0L2sb1RoXkXaRGCAfe32Pw2rIYVMSk48S\nALWqkGLbp9erQ1VEfhtj5f7uacdV9TpVXVTVxYWFhWNup9ih3LhNrI28V/Mipp06xDbVudarzT1L\nzJtvWLqrllvd+disA5lD1bJ6WTfDOQcBbKx8PjP7roaIvArAxwFsU9XH+hFvOtUUYcM/rK3U+xhp\nJ0nwuJprxRPBXFOce1YC4IifJD6RZpORFWZZud8OYLOIbBKREwFcAmBX9QQROQvATQD+UFXv61/M\nOq4eFcOinilHiA+qZgoXVSEbTasVs8yQk7yaxDSWza6G6Vy5q+qqiFwJ4GYA8wCuV9V9InJ5dnwn\ngPcBeBGAj8n4D7KqqouuhK4PDLs3v43apIqzi8QAVdu4k5V7w3UVfra6q/bXerTMLGYZqOpuALsn\nvttZef92AG/vV7RmilhUsX3z26j20bJTh9hGHc21MuSwuSpkvnD3UThsbJax7e8ymaGa/5bPz8Vr\nltFqH2PtJAmefOyNx2GfZpnKdRuOF5UZvZhlspW7YQ1jUrkXAyMBs0zMEUEkfIpFRu+hkCiv2xEt\n48MsIwLAuGXApnLPXiVih2qtj7F2kgRPaZbp2eZeue409a3FMT9x7oD9YAabyr1wNsZrjy6dxrbD\nsYhtSsenm6qQ4zk85bgq5oYPlimYy6pCWtYvJpV7kVgRsT3ala2TkKOhOtf6dC6OOsZ33eY+oEN1\nVJplrEfLmFTuKYQJugpBI+RocDbXOsprKNTLbkiFORQJVIUMkULxmZR+NmqZgX5FIUlTnWt9mmVQ\nXLfJoZrPby/RMiJjU5ThyWdTPdZWE4bvfguaQB9J+LhaudczX6cch+8kJgCwHbBhUrkX9jrjSQZt\n1As2eRaGJEt9rvU3EGvF/xqSmMrCYT6SmMR8uW2Tyr0ai2rZJtZGGQpJswzxRzWT1IHJvTnzVf3U\nc682RoeqB+qRJH5lcUalj/F2koROkWzU81yrXbchzj2PlhlyeTOOrx+/t17exKZyz15jrgpZi5bx\nLAtJF1e+n66qkKqeomW0tPX3XQlzaEwq91HxqBivs7Fq+4u0i8QApQnUzSJDGndiqmSoOmi3CYUi\nf14QDLtRSN+YVO6lycL2Y1MbWumj5Sw5Yht1NNfK5KiGUEgo5ufq5w7BSKtmGdsLK5PKPQWTBZOY\nSAi4M8tUrttw3JdZRoq1u+2ADZvKPYEY8K7BT8gQuFpIVf1mTXuoeotzz3T73NzAjfeMceVu+t63\nUg5+27G2xDa1ueYkial5dVwUDhu4/kDerjCJaXhqxYwsezxa0EofqduJL+qFwxwkMTUUJBupetms\nY6RamGVYFdIDZYKP7V/WNmp1tKPtJQkd13OtKeJNa9EyA8a5Vx2qsB2wYVO5Vx7pYtV7tXrukfaR\nGMDRXOvar2BcFTI/t792O+UCylBI44tHk8o9Hw5x76E6JuY+kvCp7eXbZ1XIjixzn3uo5o5c1pbx\nwKhYTfRrBwyJFPpIwmc0Gr/O9VzArjq+pxcOK5XssHHuZbQMzTIeSGKzjkp6NpfuxBe1Uh99xrl3\nhliql1BIYNIsY3fy2VTulZrLlm/+LMQc7knCx9Vevl0hlloJSRxyAqhq4cjlyt0Daazcx68xJ2qR\n8Kmv3B1dt6Eq5JyPaBmUPyrW9YtJ5Z7b4OYijgGv9dGzLCRdyu0ee96sWnW8CbWUdv0qI9VKm/00\nOaNY5cqdce7+mDduE2ujiJahQ5V4pEim67nOy6jwWzbXlil3Yuqnzdnk0kplGdsmUZPKvVxN2LaJ\ntZFCH0n4FOaTufrn47+utm5lp6qVNoc1y7AqpEdc15gOgVofY+0kCZ5qpvT4cz+DMY84nJOG47U2\ne2lyJsZtlQ5Vy2t3m8o9T4CI2NlY7SMhviiSmHoOS8wdpoKGxYv23+askhUOVeNPzTMpdxHZKiL7\nRWRZRK6aclxE5Ors+F4ROad/UUuKHdkbig7FQLVwGG3uxBfVuTb+3M9YzJOFmpyW9cJhAyYxjaq1\nZWzPvU7lLiLzAK4BsA3AFgCXisiWidO2Adic/dsB4Nqe5axR3ZE9VsrHYdurB2KbybnW21jMzDJN\nOXpV2/ewtWXqVSEtT71ZVu7nAlhW1ftV9TCAGwFsnzhnO4BP6ZjbAJwqImf0LGtBNUYWsF3/oYmu\nOGBChmSu55VUrrzHZplpDlU/8zumqpDrZjhnA4CHKp8PADhvhnM2AHjkuKSbwlfvW8GffXYvgNIm\nd+Hf3IrYFvGPP3UYwLiPjz55GBd+5KueJSIp8qNnngNQzrU3XP1fvSj6lSefhWAcLfPg40+vGd8/\nee5I0eZHb/kOPvP1B4+7zVn4/o+ewSknjdWiiOD2Bx53Mvf+4LUb8fbfeFnv160yi3LvDRHZgbHZ\nBmedddYxXePkk9bh4le+GAsnn4Tff+1GPHV41bRdrI2fWzgZ5//8ejz57CpX78Qbpz3/RLz5vJfi\n6eeO4Mi0jKNjYPPpJ+OXX/ICvGLDC6bO35e/+BS86byzcMrz1uHhJ37SS5uzynXu2acBAN766y/F\nl+75gZN21p98kpPrVpGuRx4R+TUA71fVi7LP7wEAVf2ryjl/B+ArqnpD9nk/gAtUtXHlvri4qEtL\nS8ffA0IISQgR2aOqi13nzWJzvx3AZhHZJCInArgEwK6Jc3YBeEsWNfM6AE+0KXZCCCFu6TTLqOqq\niFwJ4GYA8wCuV9V9InJ5dnwngN0ALgawDOBpAJe5E5kQQkgXM9ncVXU3xgq8+t3OynsFcEW/ohFC\nCDlWTGaoEkIIaYfKnRBCIoTKnRBCIoTKnRBCIoTKnRBCIqQziclZwyIrAL53DP91PYBHexZnSCzL\nb1l2wLb8lmUHbMsfmuwvVdWFrpO8KfdjRUSWZsnOChXL8luWHbAtv2XZAdvyW5WdZhlCCIkQKndC\nCIkQi8r9Ot8CHCeW5bcsO2BbfsuyA7blNym7OZs7IYSQbiyu3AkhhHRgSrl3bdQdGiLygIjcJSJ3\niMhS9t1pIvIlEfl29vpC33LmiMj1InJIRO6ufNcor4i8J/tb7BeRi/xIXcgyTfb3i8jB7P7fISIX\nV46FJPtGEblFRO4RkX0i8s7seyv3vkn+4O+/iDxPRL4hIndmsv9l9r2Je9+Kqpr4h3G54e8AeBmA\nEwHcCWCP/eNgAAACzElEQVSLb7k6ZH4AwPqJ7/4awFXZ+6sAfNC3nBXZfhPAOQDu7pIX483S7wRw\nEoBN2d9mPjDZ3w/gXVPODU32MwCck70/BcB9mYxW7n2T/MHff4y3Sj05e38CgK8DeJ2Ve9/2z9LK\nfZaNui2wHcAns/efBPC7HmWpoaq3Anh84usmebcDuFFVn1XV72Jcy//cQQSdQoPsTYQm+yOq+s3s\n/Y8B3IvxHsRW7n2T/E0EI7+OeTL7eEL2T2Hk3rdhSbk3bcIdMgrgyyKyJ9s/FgBO13KXqu8DON2P\naDPTJK+Vv8c7RGRvZrbJH62DlV1EzgbwKxivIM3d+wn5AQP3X0TmReQOAIcAfElVTd77SSwpd4uc\nr6qvAbANwBUi8pvVgzp+zjMTrmRNXgDXYmzGew2ARwB82K847YjIyQA+B+BPVfVH1WMW7v0U+U3c\nf1U9ks3TMwGcKyKvmDge/L2fhiXlfhDAxsrnM7PvgkVVD2avhwD8M8aPbz8QkTMAIHs95E/CmWiS\nN/i/h6r+IJu4IwB/j/LxOTjZReQEjBXjZ1T1puxrM/d+mvyW7j8AqOr/AbgFwFYYuvdNWFLus2zU\nHQwi8nwROSV/D+D1AO7GWOa3Zqe9FcDn/Ug4M03y7gJwiYicJCKbAGwG8A0P8jWST86MN2J8/4HA\nZBcRAfAPAO5V1Y9UDpm4903yW7j/IrIgIqdm738KwIUA/hdG7n0rvj26R/MP402478PYQ/1e3/J0\nyPoyjL3qdwLYl8sL4EUA/gPAtwF8GcBpvmWtyHwDxo/Pz2FsS3xbm7wA3pv9LfYD2Bag7J8GcBeA\nvRhPyjMClf18jB/79wK4I/t3saF73yR/8PcfwKsAfCuT8W4A78u+N3Hv2/4xQ5UQQiLEklmGEELI\njFC5E0JIhFC5E0JIhFC5E0JIhFC5E0JIhFC5E0JIhFC5E0JIhFC5E0JIhPw/sEn/G+z3X8UAAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4ee90852b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df3, df2.sensitive_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop, adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = len(df2.happy)\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(60, 1), return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(4, input_dim=1))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected lstm_11_input to have 3 dimensions, but got array with shape (322, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-3df0f60adad8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhappy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ramya/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ramya/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1552\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1553\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ramya/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    119\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected lstm_11_input to have 3 dimensions, but got array with shape (322, 1)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
